{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Twitter Scraping for Researchers\n",
    "\n",
    "This notebook was written by [John Simpson](mailto:john.simpson@computecanada.ca) and is meant to provide some simple, working examples for researchers who would like to collect information from Twitter.  While Twitter provides their own tools and libraries for this they are a little too granular and possibly unfamiliar to many in the research community.  For this reason this workbook uses a Python library build by a third party that greatly streamlines the process of collecting tweets.  Special thanks is due to Victoria Meah and Miranda Kimber for helping test earlier version of this workbook in support of their research into the impact of social media on pregnancy and fitness.\n",
    "\n",
    "This notebook assumes:\n",
    "\n",
    "1. Basic familiarity with the Jupyter Notebook environment.\n",
    "2. A functioning python environment on the system it is run in and that you have the authority to install software on it.\n",
    "3. That you have a developer account with Twitter [HERE](https://developer.twitter.com/en/)\n",
    "4. That you have an app created with Twitter [HERE](https://developer.twitter.com/en/apps)\n",
    "5. That you have a MongoDB instance set up on your machine and appropriately configured.\n",
    "6. That you pay attention to the various notes and warnings around the cells.\n",
    "\n",
    "I won't promise you any support but if you send me a note I'll help as I am able.\n",
    "\n",
    "The Python library used is called TwitterAPI (no space) and it can be found at https://github.com/geduldig/TwitterAPI.  Most of the code that is throughout this workbook is drawn directly from the examples on these pages.\n",
    "\n",
    "With all this said, let's get started by installing the TwitterAPI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TwitterAPI in /Users/simpson/anaconda3/lib/python3.7/site-packages (2.5.10)\n",
      "Requirement already satisfied: requests in /Users/simpson/anaconda3/lib/python3.7/site-packages (from TwitterAPI) (2.23.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/simpson/anaconda3/lib/python3.7/site-packages (from TwitterAPI) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/simpson/anaconda3/lib/python3.7/site-packages (from requests->TwitterAPI) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/simpson/anaconda3/lib/python3.7/site-packages (from requests->TwitterAPI) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/simpson/anaconda3/lib/python3.7/site-packages (from requests->TwitterAPI) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/simpson/anaconda3/lib/python3.7/site-packages (from requests->TwitterAPI) (2020.4.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/simpson/anaconda3/lib/python3.7/site-packages (from requests-oauthlib->TwitterAPI) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install TwitterAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the TwitterAPI library installed on the system we should be able to open it for use throughout this workbook with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note that almost every piece of code in the remainder of this workbook assumes that the two cells above have been run and run successfully.  If you open the workbook and immediately try to run a cell other than this one first then it is likely that you will receive an error.  Simply run the cells above and try to run the cell you want to run again.  If you are receiving errors then two likely possibilities are an incorrect installation of Python or no network connection.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of this workbook‚Äìand the Twitter Developer API (Application Programming Interface) in general‚Äîrequires a developer account from Twitter.  Unlike the early days of Twitter when anyone with a regular Twitter account who requested a developer account would just be given one, Twitter now screens requests for developer accounts, a process that can stall getting started by many days.  If you had a developer account previously and created applications (apps) that used the Twitter application programming interfaces (APIs) then you may still be able to use these apps to do some work but it is possible that their ability to access the Twitter archive has been reduced and, if so, that you'll need to apply for a new developer account to correct this.  A developer account may be requested from https://developer.twitter.com/en/apply/user (assuming you already have a regular Twitter account).\n",
    "\n",
    "As the [TwitterAPI Documentation](https://geduldig.github.io/TwitterAPI/authentication.html) points out: _Twitter supports both user and application authentication, called oAuth 1 and oAuth 2, respectively. User authentication gives you access to all API endpoints, basically read and write persmission. It is also required in order to using the Streaming API. Application authentication gives you access to just the read portion of the API ‚Äì so, no creating or destroying tweets. Application authentication, however, has elevated rate limits._ \n",
    "\n",
    "We will use oAuth1 throughout this workbook even though we'll only be reading tweets since it can be used in more situations (in particular when we try to read from the streaming API).  If it is necessary to read Twitter API endpoints (other than the streaming endpoint) at a faster rate than this workbook initially provides then consider switching to oAuth2.\n",
    "\n",
    "You will need oAuth1 to do any of the following:\n",
    "\n",
    "* Post Tweets or other resources;\n",
    "* Connect to Streaming endpoints;\n",
    "* Search for users;\n",
    "* Use any geo endpoint;\n",
    "* Access Direct Messages or account credentials;\n",
    "* Retrieve user's email addresses;\n",
    "\n",
    "You can get away with oAuth2 (or application-only authentication) if you are only looking to perform the following:\n",
    "\n",
    "* Pull user timelines;\n",
    "* Access friends and followers of any account;\n",
    "* Access lists resources;\n",
    "* Search in Tweets;\n",
    "* Retrieve any user information, excluding the user's email address;\n",
    "\n",
    "Both authentication methods will require you to collect some information about keys and tokens and paste it into the appropriate section of the cell below.  This key and token information is generated when you create a profile for an app on the Twitter Developer site.  App profiles can be created at https://developer.twitter.com/en/apps.  That same page will hold a list of all the profiles that you have created and clicking on the \"Details\" button for each app will bring you to a summary page.  There will be a link/tab near the top of the page called \"Keys and Tokens\" and clicking this will bring you to the page with the key and token information.\n",
    "\n",
    "Paste in the required key and token information from the Twitter Developer site into the cell below and then run it in order to use this workbook.  Remember that you'll need to run the cell below (which loads your credentials) and _one_ of the authorization methods below (default to oAuth1 unless you are sure you need oAuth2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'VZn9a35jQsIcNDUSH8GCFfk2c'\n",
    "API_KEY_SECRET = 'jUyu69HeCHuxepY1j2LvFZmwWTVHSGXATlvoLQ34U2E6LQjNRn'\n",
    "ACCESS_TOKEN = '557113581-S5yxV6FXDQUPm0Ih3AjbgvOBxLwvqJaghjtlrVRQ'\n",
    "ACCESS_TOKEN_SECRET = 'eBghW3C9qglDBlFRpSNxfmQTEbfGkp8RbpKPhLkLyhuwm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! IMPORTANT !!!\n",
    "\n",
    "If the code in the cells below fails it is likely because you need to put your own authentication details in the cell above.  More specifically, you will need to copy-paste in the api key, api key secret, access token, and access token secret from the \"keys and tokens\" tab of the description of the app that you set up with your Twitter developer account.\n",
    "\n",
    "!!! IMPORTANT !!!\n",
    "\n",
    "### oAuth1 (User Identification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<requests_oauthlib.oauth1_auth.OAuth1 at 0x7f9c094f0210>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = TwitterAPI(API_KEY, \n",
    "                 API_KEY_SECRET, \n",
    "                 ACCESS_TOKEN, \n",
    "                 ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api.auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If successful the output of the cell above should look something like:\n",
    "\n",
    "    <requests_oauthlib.oauth1_auth.OAuth1 at 0x107b8bba8>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oAuth2 (App Identification)\n",
    "!!!WARNING!!! \n",
    "\n",
    "Using oAuth2 will prevent you from using the streaming endpoint.  If you choose to try oAuth2 in the streaming example and receive the following error\n",
    "\n",
    "    TwitterRequestError: Twitter request failed (401)\n",
    "\n",
    "then simply run the oAuth1 section and then try the streaming portion of this workbook again.\n",
    "\n",
    "!!!WARNING!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TwitterAPI.BearerAuth.BearerAuth at 0x7f9c09488f90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = TwitterAPI(API_KEY,\n",
    "                 API_KEY_SECRET,\n",
    "                 auth_type='oAuth2')\n",
    "\n",
    "api.auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If successful the output of the cell above should look something like:\n",
    "\n",
    "    <TwitterAPI.BearerAuth.BearerAuth at 0x107b9acc0>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a tweet, _really_ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that most people use \"tweet\" to refer to snippets of text that are usually 140 characters or less (But can now be up to 280 characters) most people are generally surprised to discover that this is only the proverbial \"tip of the iceberg\" in terms of what a tweet really is.  In this section we'll see exactly what a tweet is, how to improve looking at the full content, and then how to grab the portions that we want (usually the \"text\").\n",
    "\n",
    "To make this easy we'll only request a single tweet by its ID number.  Every tweet has its own unique ID and can be requested if that ID is known.  We request the tweet with ID# 210462857140252672 and then print the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TwitterAPI.TwitterAPI.TwitterResponse object at 0x7f9c097c8d90>\n"
     ]
    }
   ],
   "source": [
    "r = api.request('statuses/show/:%d' % 1270422899195817986)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of running the cell above will be something like `<TwitterAPI.TwitterAPI.TwitterResponse object at 0x107b9af28>`, which isn't quite what we are looking for.  This `TwitterResponse object` is a bundle of information related to the request including status code returned (`r.status_code`), how much of your quota is left (`r.get_quota`), the response headers (`r.headers`), etc.  What we wantis the \"text\" portion of this response (`r.text`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"created_at\":\"Tue Jun 09 18:29:57 +0000 2020\",\"id\":1270422899195817986,\"id_str\":\"1270422899195817986\",\"text\":\"From my hometown, Cheyenne translation of Black Lives Matter. \\\\nM\\\\u00f2\\\\u022fht\\\\u0227ev\\\\u00e9\\'h\\\\u00f2e h\\\\u00e9v\\\\u00f2\\\\u0117stan\\\\u00e9hevesto\\\\u00e9va \\\\u00e9h\\\\u00e8\\\\u0227m\\\\u022femenestse https:\\\\/\\\\/t.co\\\\/T7mWYkzF29\",\"truncated\":false,\"entities\":{\"hashtags\":[],\"symbols\":[],\"user_mentions\":[],\"urls\":[],\"media\":[{\"id\":1270417788184731651,\"id_str\":\"1270417788184731651\",\"indices\":[114,137],\"media_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/EaFuP1UWoAMQF2z.jpg\",\"media_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/EaFuP1UWoAMQF2z.jpg\",\"url\":\"https:\\\\/\\\\/t.co\\\\/T7mWYkzF29\",\"display_url\":\"pic.twitter.com\\\\/T7mWYkzF29\",\"expanded_url\":\"https:\\\\/\\\\/twitter.com\\\\/CoreyWelch_STEM\\\\/status\\\\/1270422899195817986\\\\/photo\\\\/1\",\"type\":\"photo\",\"sizes\":{\"thumb\":{\"w\":150,\"h\":150,\"resize\":\"crop\"},\"small\":{\"w\":680,\"h\":680,\"resize\":\"fit\"},\"medium\":{\"w\":1200,\"h\":1200,\"resize\":\"fit\"},\"large\":{\"w\":1440,\"h\":1440,\"resize\":\"fit\"}}}]},\"extended_entities\":{\"media\":[{\"id\":1270417788184731651,\"id_str\":\"1270417788184731651\",\"indices\":[114,137],\"media_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/EaFuP1UWoAMQF2z.jpg\",\"media_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/EaFuP1UWoAMQF2z.jpg\",\"url\":\"https:\\\\/\\\\/t.co\\\\/T7mWYkzF29\",\"display_url\":\"pic.twitter.com\\\\/T7mWYkzF29\",\"expanded_url\":\"https:\\\\/\\\\/twitter.com\\\\/CoreyWelch_STEM\\\\/status\\\\/1270422899195817986\\\\/photo\\\\/1\",\"type\":\"photo\",\"sizes\":{\"thumb\":{\"w\":150,\"h\":150,\"resize\":\"crop\"},\"small\":{\"w\":680,\"h\":680,\"resize\":\"fit\"},\"medium\":{\"w\":1200,\"h\":1200,\"resize\":\"fit\"},\"large\":{\"w\":1440,\"h\":1440,\"resize\":\"fit\"}}}]},\"source\":\"\\\\u003ca href=\\\\\"https:\\\\/\\\\/mobile.twitter.com\\\\\" rel=\\\\\"nofollow\\\\\"\\\\u003eTwitter Web App\\\\u003c\\\\/a\\\\u003e\",\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":1915514191,\"id_str\":\"1915514191\",\"name\":\"Corey Welch\",\"screen_name\":\"CoreyWelch_STEM\",\"location\":\"Ames, IA\",\"description\":\"Director\\\\/Founder, STEM Scholars Program for UR-students. Zoologist, Northern Cheyenne. @SACNAS Board Member 2016-2021, @IowaStateU My views\",\"url\":\"https:\\\\/\\\\/t.co\\\\/bRxf9Fbwgp\",\"entities\":{\"url\":{\"urls\":[{\"url\":\"https:\\\\/\\\\/t.co\\\\/bRxf9Fbwgp\",\"expanded_url\":\"https:\\\\/\\\\/stem.las.iastate.edu\\\\/\",\"display_url\":\"stem.las.iastate.edu\",\"indices\":[0,23]}]},\"description\":{\"urls\":[]}},\"protected\":false,\"followers_count\":3099,\"friends_count\":1657,\"listed_count\":110,\"created_at\":\"Sat Sep 28 22:13:37 +0000 2013\",\"favourites_count\":39132,\"utc_offset\":null,\"time_zone\":null,\"geo_enabled\":true,\"verified\":false,\"statuses_count\":18209,\"lang\":null,\"contributors_enabled\":false,\"is_translator\":false,\"is_translation_enabled\":false,\"profile_background_color\":\"C0DEED\",\"profile_background_image_url\":\"http:\\\\/\\\\/abs.twimg.com\\\\/images\\\\/themes\\\\/theme1\\\\/bg.png\",\"profile_background_image_url_https\":\"https:\\\\/\\\\/abs.twimg.com\\\\/images\\\\/themes\\\\/theme1\\\\/bg.png\",\"profile_background_tile\":false,\"profile_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/378800000541241885\\\\/aa34d942099111e694e3bb50ddb93568_normal.jpeg\",\"profile_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/378800000541241885\\\\/aa34d942099111e694e3bb50ddb93568_normal.jpeg\",\"profile_banner_url\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_banners\\\\/1915514191\\\\/1535047970\",\"profile_link_color\":\"1DA1F2\",\"profile_sidebar_border_color\":\"C0DEED\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"has_extended_profile\":true,\"default_profile\":true,\"default_profile_image\":false,\"following\":false,\"follow_request_sent\":false,\"notifications\":false,\"translator_type\":\"none\"},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":342,\"favorite_count\":1612,\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"possibly_sensitive_appealable\":false,\"lang\":\"ht\"}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot more than 140 characters!\n",
    "\n",
    "Exactly what is there is hard to determine though given the formatting.  We can do better.\n",
    "\n",
    "This content is in is JavaScript Object Notation (JSON), which is really a nested list of properties.  Python doesn't know this is JSON though so we need to tell it.  We do this in the next cell by importing the `json` library, converting `r.text` to json using the load string method ( `.loads()` ), and then outputting that json with formatting using the output string method ( `.dumps()` ) with some some options added for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"contributors\": null,\n",
      "   \"coordinates\": null,\n",
      "   \"created_at\": \"Tue Jun 09 18:29:57 +0000 2020\",\n",
      "   \"entities\": {\n",
      "      \"hashtags\": [],\n",
      "      \"media\": [\n",
      "         {\n",
      "            \"display_url\": \"pic.twitter.com/T7mWYkzF29\",\n",
      "            \"expanded_url\": \"https://twitter.com/CoreyWelch_STEM/status/1270422899195817986/photo/1\",\n",
      "            \"id\": 1270417788184731651,\n",
      "            \"id_str\": \"1270417788184731651\",\n",
      "            \"indices\": [\n",
      "               114,\n",
      "               137\n",
      "            ],\n",
      "            \"media_url\": \"http://pbs.twimg.com/media/EaFuP1UWoAMQF2z.jpg\",\n",
      "            \"media_url_https\": \"https://pbs.twimg.com/media/EaFuP1UWoAMQF2z.jpg\",\n",
      "            \"sizes\": {\n",
      "               \"large\": {\n",
      "                  \"h\": 1440,\n",
      "                  \"resize\": \"fit\",\n",
      "                  \"w\": 1440\n",
      "               },\n",
      "               \"medium\": {\n",
      "                  \"h\": 1200,\n",
      "                  \"resize\": \"fit\",\n",
      "                  \"w\": 1200\n",
      "               },\n",
      "               \"small\": {\n",
      "                  \"h\": 680,\n",
      "                  \"resize\": \"fit\",\n",
      "                  \"w\": 680\n",
      "               },\n",
      "               \"thumb\": {\n",
      "                  \"h\": 150,\n",
      "                  \"resize\": \"crop\",\n",
      "                  \"w\": 150\n",
      "               }\n",
      "            },\n",
      "            \"type\": \"photo\",\n",
      "            \"url\": \"https://t.co/T7mWYkzF29\"\n",
      "         }\n",
      "      ],\n",
      "      \"symbols\": [],\n",
      "      \"urls\": [],\n",
      "      \"user_mentions\": []\n",
      "   },\n",
      "   \"extended_entities\": {\n",
      "      \"media\": [\n",
      "         {\n",
      "            \"display_url\": \"pic.twitter.com/T7mWYkzF29\",\n",
      "            \"expanded_url\": \"https://twitter.com/CoreyWelch_STEM/status/1270422899195817986/photo/1\",\n",
      "            \"id\": 1270417788184731651,\n",
      "            \"id_str\": \"1270417788184731651\",\n",
      "            \"indices\": [\n",
      "               114,\n",
      "               137\n",
      "            ],\n",
      "            \"media_url\": \"http://pbs.twimg.com/media/EaFuP1UWoAMQF2z.jpg\",\n",
      "            \"media_url_https\": \"https://pbs.twimg.com/media/EaFuP1UWoAMQF2z.jpg\",\n",
      "            \"sizes\": {\n",
      "               \"large\": {\n",
      "                  \"h\": 1440,\n",
      "                  \"resize\": \"fit\",\n",
      "                  \"w\": 1440\n",
      "               },\n",
      "               \"medium\": {\n",
      "                  \"h\": 1200,\n",
      "                  \"resize\": \"fit\",\n",
      "                  \"w\": 1200\n",
      "               },\n",
      "               \"small\": {\n",
      "                  \"h\": 680,\n",
      "                  \"resize\": \"fit\",\n",
      "                  \"w\": 680\n",
      "               },\n",
      "               \"thumb\": {\n",
      "                  \"h\": 150,\n",
      "                  \"resize\": \"crop\",\n",
      "                  \"w\": 150\n",
      "               }\n",
      "            },\n",
      "            \"type\": \"photo\",\n",
      "            \"url\": \"https://t.co/T7mWYkzF29\"\n",
      "         }\n",
      "      ]\n",
      "   },\n",
      "   \"favorite_count\": 1612,\n",
      "   \"favorited\": false,\n",
      "   \"geo\": null,\n",
      "   \"id\": 1270422899195817986,\n",
      "   \"id_str\": \"1270422899195817986\",\n",
      "   \"in_reply_to_screen_name\": null,\n",
      "   \"in_reply_to_status_id\": null,\n",
      "   \"in_reply_to_status_id_str\": null,\n",
      "   \"in_reply_to_user_id\": null,\n",
      "   \"in_reply_to_user_id_str\": null,\n",
      "   \"is_quote_status\": false,\n",
      "   \"lang\": \"ht\",\n",
      "   \"place\": null,\n",
      "   \"possibly_sensitive\": false,\n",
      "   \"possibly_sensitive_appealable\": false,\n",
      "   \"retweet_count\": 342,\n",
      "   \"retweeted\": false,\n",
      "   \"source\": \"<a href=\\\"https://mobile.twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web App</a>\",\n",
      "   \"text\": \"From my hometown, Cheyenne translation of Black Lives Matter. \\nM\\u00f2\\u022fht\\u0227ev\\u00e9'h\\u00f2e h\\u00e9v\\u00f2\\u0117stan\\u00e9hevesto\\u00e9va \\u00e9h\\u00e8\\u0227m\\u022femenestse https://t.co/T7mWYkzF29\",\n",
      "   \"truncated\": false,\n",
      "   \"user\": {\n",
      "      \"contributors_enabled\": false,\n",
      "      \"created_at\": \"Sat Sep 28 22:13:37 +0000 2013\",\n",
      "      \"default_profile\": true,\n",
      "      \"default_profile_image\": false,\n",
      "      \"description\": \"Director/Founder, STEM Scholars Program for UR-students. Zoologist, Northern Cheyenne. @SACNAS Board Member 2016-2021, @IowaStateU My views\",\n",
      "      \"entities\": {\n",
      "         \"description\": {\n",
      "            \"urls\": []\n",
      "         },\n",
      "         \"url\": {\n",
      "            \"urls\": [\n",
      "               {\n",
      "                  \"display_url\": \"stem.las.iastate.edu\",\n",
      "                  \"expanded_url\": \"https://stem.las.iastate.edu/\",\n",
      "                  \"indices\": [\n",
      "                     0,\n",
      "                     23\n",
      "                  ],\n",
      "                  \"url\": \"https://t.co/bRxf9Fbwgp\"\n",
      "               }\n",
      "            ]\n",
      "         }\n",
      "      },\n",
      "      \"favourites_count\": 39132,\n",
      "      \"follow_request_sent\": false,\n",
      "      \"followers_count\": 3099,\n",
      "      \"following\": false,\n",
      "      \"friends_count\": 1657,\n",
      "      \"geo_enabled\": true,\n",
      "      \"has_extended_profile\": true,\n",
      "      \"id\": 1915514191,\n",
      "      \"id_str\": \"1915514191\",\n",
      "      \"is_translation_enabled\": false,\n",
      "      \"is_translator\": false,\n",
      "      \"lang\": null,\n",
      "      \"listed_count\": 110,\n",
      "      \"location\": \"Ames, IA\",\n",
      "      \"name\": \"Corey Welch\",\n",
      "      \"notifications\": false,\n",
      "      \"profile_background_color\": \"C0DEED\",\n",
      "      \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "      \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "      \"profile_background_tile\": false,\n",
      "      \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/1915514191/1535047970\",\n",
      "      \"profile_image_url\": \"http://pbs.twimg.com/profile_images/378800000541241885/aa34d942099111e694e3bb50ddb93568_normal.jpeg\",\n",
      "      \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/378800000541241885/aa34d942099111e694e3bb50ddb93568_normal.jpeg\",\n",
      "      \"profile_link_color\": \"1DA1F2\",\n",
      "      \"profile_sidebar_border_color\": \"C0DEED\",\n",
      "      \"profile_sidebar_fill_color\": \"DDEEF6\",\n",
      "      \"profile_text_color\": \"333333\",\n",
      "      \"profile_use_background_image\": true,\n",
      "      \"protected\": false,\n",
      "      \"screen_name\": \"CoreyWelch_STEM\",\n",
      "      \"statuses_count\": 18209,\n",
      "      \"time_zone\": null,\n",
      "      \"translator_type\": \"none\",\n",
      "      \"url\": \"https://t.co/bRxf9Fbwgp\",\n",
      "      \"utc_offset\": null,\n",
      "      \"verified\": false\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "parsed_r = json.loads(r.text)\n",
    "print(json.dumps(parsed_r, indent=3, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much nicer to read, especially since the various components have been alphabetized.  Having the response text as JSON also allows us to easily access each subcomponent.  We show this in the next cell by printing the text (sometimes called the \"body\" of the tweet), the ID# of the tweet, and the screen name of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet Body:  Where was Richard running today? https://t.co/i7QT7MLG75\n",
      "Tweet ID:  1230671342866821121\n",
      "Screen Name:  R_Sigurdson\n",
      "Declared User Location:  Calgary, Alberta\n"
     ]
    }
   ],
   "source": [
    "print(\"Tweet Body: \",parsed_r['text'])\n",
    "print(\"Tweet ID: \",parsed_r['id'])\n",
    "print(\"Screen Name: \",parsed_r['user']['screen_name'])\n",
    "print(\"Declared User Location: \", parsed_r['user']['location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than parse the output to JSON everytime we can combine the Twitter Response Object's `.get_iterator()` method with a for-loop to do this directly.  It's less work overall and is cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = api.request('statuses/show/:%d' % 210462857140252672)\n",
    "for item in r.get_iterator():\n",
    "    print(\"Tweet Body: \",item['text'])\n",
    "    print(\"Tweet ID: \",item['id'])\n",
    "    print(\"Screen Name: \",item['user']['screen_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Codes\n",
    "As we move forward, eventually you're likely to end up with an error.  When these are related to our interaction with Twitter rather than a more local mistake then Twitter helpfully provides a code to help diagnose the problem.  A list of all these codes is [HERE](https://developer.twitter.com/en/docs/basics/response-codes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the entire API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With what you have in hand you now have the ability to request anything from the entire API.  If the API serves it then you can get it.  For a list of what is on the menu see [HERE](https://developer.twitter.com/en/docs/api-reference-index).  All that is missing is how to modify the request to grab any of that information and that's exactly what we'll cover in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block below we grab the ids of the followers associated with the Twitter Handle passed to the variable \"TwitterHandle\".  This will return only the ids of the followers but it will return up to 5,000 at a time.\n",
    "\n",
    "[To add: Example with likes and retweets.  \"I suspect that what you want are the IDs of the retweeters for a specific tweet.¬†¬†And/Or all those who liked a specific tweet.¬†¬†You can get the first fairly directly by looking at the API Reference [HERE](https://developer.twitter.com/en/docs/api-reference-index) and searching for ‚Äúretweet‚Äù to see what you can GET (See ‚ÄúAccessing the entire API‚Äù in the notebook for an example with IDs).¬†¬†Favourites is tougher.¬†¬†You can get all the favourite tweets of a user but not all the users who favourited a tweet (at least if you can I don‚Äôt know how to do it directly).¬†¬†Look at the API reference and search ‚ÄúFavorite‚Äù to see how.\"\n",
    "\n",
    "also: Media.  \"How does the scraper deal with media?¬†¬†The short answer: it doesn‚Äôt.¬†¬†Why?¬†¬†Media are just values/links in the JSON objects that are returned.¬†¬†If you want the actual media then you‚Äôll need to follow the links to see what is there and capture it another way (possibly with Python but outside the scraper).¬†¬†For example try this (assuming the previous stuff in the notebook to the very first example that pulls a tweet by ID):\n",
    "\n",
    "`import json`\n",
    "\n",
    "`r = api.request('statuses/show/:%d' % 1270422899195817986)`\n",
    "\n",
    "`parsed_r = json.loads(r.text)`\n",
    "\n",
    "`print(json.dumps(parsed_r, indent=3, sort_keys=True))`\n",
    "\n",
    "You‚Äôll see some ‚Äúmedia‚Äù keys that hold the links to what you want, such as ‚Äúhttp://pbs.twimg.com/media/EaFuP1UWoAMQF2z.jpg‚Äù.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"ids\":[89597974,354740435,2809015377,293651076,743086431971778561,154793244,468571696,1155634482629791746,59819048,14726818,1468480220,2831073533,326077427,7465672,1142871446,15280441,108797530,3280014502,1281391231,20655405,85698409,1106125130529497093,201729872,634145696,317837804,2530913857,108366404,1009540472363077632,706961700000411649,3004785682,1275919560,2794614248,377648815,7737262,1061902105,65767723,273333980,935257516669272064,1875230906,2163496622,4490863694,975385941039812608,974688967193841669,958828880684462080,395545900,54840028,923351385810309120,88226196,21900557,113369924,229303281,4274106434,2364592844,365770640,66843277,775740202576781312,804234421331107841,915060319260639232,2902074361,915705393732562945,914617820914356225,335027958,280168233,91616458,236361035,1398709159,892836988612509696,730541257299251201,890993297727963136,44410209,1020311,489956375,880115301743960064,53893339,416157021,345642306,75694920,279097061,3133107355,46712597,319103163,1413925345,1341757860,14605422,104747951,739521654,2649151488,17841670,702633249483440128,195638261,859779431849574400,3033215139,771941738835484673,718282232914440192,1957569859,50122046,857135565812236288,218830003,851159793117081600,399723382,840464287881650180,3431536774,2463633734,296392522,22643508,270165350,1899140628,838788066651230208,291826682,828095105030561792,824351166221803520,247479889,55206008,2803818654,4060974927,701320815,174910671,822838070873444352,1902575138,607602141,311140741,3473906057,2336052588,39444999,768838790425284608,404929804,701850256162459648,3170285824,759969038386683904,759937282774151168,23150071,996176930,601148075,172496319,329218487,23698066,35402085,1305940272,949827631,132464159,96445187,17201942,11448222,142362713,102648212,3603106394,26542532,370817386,19040631,729450727526010885,2252381059,3283541041,156437682,3248172260,190003722,17871090,10049682,14600216,3294503833,2314159489,72199429,785673708,1296995448,14248871,6482762,48092573,95571923,1160468492,14959360,729146452711116800,728953955519102976,164478889,1410349332,200306226,224393371,720354332332281858,88764812,2281067622,712053239034695681,18469790,79639787,14054390,702093941798096896,5537702,1735489123,4898290400,4828432228,3289991393,2903975268,2165821830,3146802239,3182197459,2224364514,467094122,153070745,4831408613,2764641745,4746194492,242454033,266584947,3193178697,628624153,192031003,1444207020,2991293020,2563711675,1762432520,4139781303,1154916386,2584167966,3973479372,347350842,1115649174,39569710,3235383289,21071900,3213687383,132310937,2260684555,3641425574,1445257722,2395940738,3659297055,1684172437,1442346535,35849829,308771061,3340718660,48051873,3436070188,3420613522,1374976800,881314182,2588933226,3303176678,529452973,22739030,16462809,20302424,3377929420,153535280,42820326,32216605,3373097049,61625084,1888836121,12876812,113056960,807724747,449932790,181578350,385137534,1113486734,3252815892,1528526695,3244537232,140579170,142828675,3251403566,3327082882,2238308401,831828900,58143964,1367496151,169696642,22990120,10832182,83301597,176245614,239930480,282855642,490989698,1148933959,2334516805,6667212,1855362589,51271746,2972398143,56281801,960637746,2151572335,389005082,14084406,786967358,239846241,16656420,3365101,2982077061,88095677,14221013,15842692,713957226,21248549,1086423054,12043242,2187207564,43453491,2354881,1730020453,3226649180,63363850,807717,3119445995,253213098,197497977,24012732,3183050702,883576080,2789796048,1618483388,380453662,3171057312,3166181091,24092133,224734204,2883187155,160346651,18059285,14905093,581312485,2823465657,25587808,3066444694,3130042396,887015516,481441553,798123,2845875151,3066558769,15474609,3035180686,488733624,135918180,48309940,3008503616,3000102625,2348955666,2991616404,1071754602,285129458,72699258,2473458703,2415523448,596230865,2918247750,542783281,255681367,363591541,2933931003,2933011539,2931005211,122327464,14844898,90116279,2922078584,1311963594,1024855752,2851684143,2887292061,2855818356,2543312586,432091282,107943025,313686789,2868171995,626417829,2447674574,1798778112,347315069,384389732,2827513359,948016303,473940816,507438295,16684998,1044155796,2612166614,1513437702,180574385,1019938340,2714653874,2701611164,848300586,2677453872,36128926,110465562,2595394993,2189954748,201224682,864701,10161492,226521252,468522356,1616773572,114528144,64721582,58073253,2491288094,564253432,130904352,106630852,300314312,23518766,119342754,283359358,522483755,2561636414,2263274264,19693148,783732,2569531446,385975720,776421925,14258500,2544102674,915117859,1932267068,2551254786,2345758813,769099,13449272,180007382,154261693,21764132,350387334,904193552,1199595018,856560396,17079605,22214241,24985150,898440589,14221870,178082190,280578582,584615187,447178767,25471291,575962369,92381471,36060574,25759631,2359651063,23865342,310403001,86649839,91939908,262493093,901847216,253865251,54942179,27251713,27525925,93659142,1511696282,244459958,410331345,42482549,2415196886,936961322,16260741,534825327,1901098152,2383048152,39664676,258934532,50182356,2367088476,222904627,293803288,1430255593,182959326,1364869201,61762488,25366013,326822288,1908536910,21259042,20738733,599546734,221201900,851928439,2287067575,456849145,21966494,63115240,1258464445,516083888,413257620,460727669,767753456,50116100,90549534,416608920,112610515,66129085,57145683,54163837,29280555,1879878343,50022680,1413216074,41965769,34607715,1027226198,734568919,72453833,16149989,281832082,1286732425,124920374,35025484,91438333,722546894,565821657,1547236134,620416416,41281783,259876451,182412496,313327707,17565098,115721324,16841386,19193598,38471570,99580390,317429351,515787374,27251529,25209036,876962514,56995315,1355268848,1279934497,392834323,1014509647,558243883,1107178256,1153281972,19251811,84614189,1127013486,337814894,84860294,15704731,48400074,551426258,997762452,19934239,196411320,164700688,807606572,180504932,85875442,498245013,860416675,119823957,312499605,818740194,808220234,126154552,742111879,719113164,85396548,235198532,16440912,14174119,367463832],\"next_cursor\":0,\"next_cursor_str\":\"0\",\"previous_cursor\":0,\"previous_cursor_str\":\"0\",\"total_count\":null}'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterHandle = 'symulation'\n",
    "\n",
    "r = api.request('followers/ids', {'screen_name': TwitterHandle})\n",
    "\n",
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block below we grab the actual JSON entries on followers for the twitter handle passed.  This returns a lot more information than just the id but it only returns up to 20 at a time.  If you wanted more then you'd need to use paging, as described below.  \n",
    "\n",
    "Note the use of the `get_iterator` method to help parse the JSON that is returned into user by user chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 89597974, 'id_str': '89597974', 'name': 'üÖºüÖ¥üÖªüÖæüÖ≥üÜà üÖ∂üÜÅüÖ¥üÖ¥üÖΩ', 'screen_name': 'Melody_36582', 'location': 'üìç Canada üá®üá¶', 'description': \"Follow me, follow me, and don't forget the whiskey üíã\", 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 3, 'friends_count': 291, 'listed_count': 1, 'created_at': 'Fri Nov 13 01:48:23 +0000 2009', 'favourites_count': 0, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 30, 'lang': None, 'status': {'created_at': 'Sun May 03 23:01:54 +0000 2020', 'id': 1257082986497015809, 'id_str': '1257082986497015809', 'text': 'Follow Your Heart But Take Your Brain With You. üíùüëÖüíñ\\nhttps://t.co/CLYWsgzZAT', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [], 'media': [{'id': 1254935218739445761, 'id_str': '1254935218739445761', 'indices': [52, 75], 'media_url': 'http://pbs.twimg.com/media/EWps7rkXgAEehUe.jpg', 'media_url_https': 'https://pbs.twimg.com/media/EWps7rkXgAEehUe.jpg', 'url': 'https://t.co/CLYWsgzZAT', 'display_url': 'pic.twitter.com/CLYWsgzZAT', 'expanded_url': 'https://twitter.com/Terrie_49592/status/1254935227170000897/photo/1', 'type': 'photo', 'sizes': {'large': {'w': 1280, 'h': 1280, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'small': {'w': 680, 'h': 680, 'resize': 'fit'}, 'medium': {'w': 1200, 'h': 1200, 'resize': 'fit'}}, 'source_status_id': 1254935227170000897, 'source_status_id_str': '1254935227170000897', 'source_user_id': 33724440, 'source_user_id_str': '33724440'}]}, 'extended_entities': {'media': [{'id': 1254935218739445761, 'id_str': '1254935218739445761', 'indices': [52, 75], 'media_url': 'http://pbs.twimg.com/media/EWps7rkXgAEehUe.jpg', 'media_url_https': 'https://pbs.twimg.com/media/EWps7rkXgAEehUe.jpg', 'url': 'https://t.co/CLYWsgzZAT', 'display_url': 'pic.twitter.com/CLYWsgzZAT', 'expanded_url': 'https://twitter.com/Terrie_49592/status/1254935227170000897/photo/1', 'type': 'photo', 'sizes': {'large': {'w': 1280, 'h': 1280, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'small': {'w': 680, 'h': 680, 'resize': 'fit'}, 'medium': {'w': 1200, 'h': 1200, 'resize': 'fit'}}, 'source_status_id': 1254935227170000897, 'source_status_id_str': '1254935227170000897', 'source_user_id': 33724440, 'source_user_id_str': '33724440'}]}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Mobile Web (M2)</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1257082732636598274/gVXuPL09_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1257082732636598274/gVXuPL09_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/89597974/1588546891', 'profile_link_color': '0084B4', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 354740435, 'id_str': '354740435', 'name': 'üÖ±üÖ¥üÜÉüÜÉüÖ∏üÖ¥ üÜÉüÖ∞üÜàüÖªüÖæüÜÅ', 'screen_name': 'Bettie_37703', 'location': 'üìç Canada üá®üá¶', 'description': \"Follow me, follow me, and don't forget the whiskey üíãüçë\", 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 6, 'friends_count': 214, 'listed_count': 0, 'created_at': 'Sun Aug 14 06:33:05 +0000 2011', 'favourites_count': 0, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 30, 'lang': None, 'status': {'created_at': 'Sun May 03 20:14:27 +0000 2020', 'id': 1257040847176118272, 'id_str': '1257040847176118272', 'text': 'Heyyy Guys...üçìüëÖüçì\\nhttps://t.co/mRsvgWr5Rj', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [], 'media': [{'id': 1254935218739445761, 'id_str': '1254935218739445761', 'indices': [17, 40], 'media_url': 'http://pbs.twimg.com/media/EWps7rkXgAEehUe.jpg', 'media_url_https': 'https://pbs.twimg.com/media/EWps7rkXgAEehUe.jpg', 'url': 'https://t.co/mRsvgWr5Rj', 'display_url': 'pic.twitter.com/mRsvgWr5Rj', 'expanded_url': 'https://twitter.com/Terrie_49592/status/1254935227170000897/photo/1', 'type': 'photo', 'sizes': {'large': {'w': 1280, 'h': 1280, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'small': {'w': 680, 'h': 680, 'resize': 'fit'}, 'medium': {'w': 1200, 'h': 1200, 'resize': 'fit'}}, 'source_status_id': 1254935227170000897, 'source_status_id_str': '1254935227170000897', 'source_user_id': 33724440, 'source_user_id_str': '33724440'}]}, 'extended_entities': {'media': [{'id': 1254935218739445761, 'id_str': '1254935218739445761', 'indices': [17, 40], 'media_url': 'http://pbs.twimg.com/media/EWps7rkXgAEehUe.jpg', 'media_url_https': 'https://pbs.twimg.com/media/EWps7rkXgAEehUe.jpg', 'url': 'https://t.co/mRsvgWr5Rj', 'display_url': 'pic.twitter.com/mRsvgWr5Rj', 'expanded_url': 'https://twitter.com/Terrie_49592/status/1254935227170000897/photo/1', 'type': 'photo', 'sizes': {'large': {'w': 1280, 'h': 1280, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'small': {'w': 680, 'h': 680, 'resize': 'fit'}, 'medium': {'w': 1200, 'h': 1200, 'resize': 'fit'}}, 'source_status_id': 1254935227170000897, 'source_status_id_str': '1254935227170000897', 'source_user_id': 33724440, 'source_user_id_str': '33724440'}]}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Mobile Web (M2)</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1257040565042110464/-4P_sbsp_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1257040565042110464/-4P_sbsp_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/354740435/1588536837', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 2809015377, 'id_str': '2809015377', 'name': 'Jordan Smith', 'screen_name': 'JPSmithNL', 'location': '', 'description': 'Hardware, software, tupperware. Machine learning enthusiast @Verafin, tweets are mine.', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 149, 'friends_count': 1144, 'listed_count': 5, 'created_at': 'Sun Oct 05 20:35:50 +0000 2014', 'favourites_count': 4109, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 948, 'lang': None, 'status': {'created_at': 'Tue May 26 00:29:02 +0000 2020', 'id': 1265077449500565504, 'id_str': '1265077449500565504', 'text': 'RT @PepperoniDeluxe: You guys went through my fantasy city like truffle pigs, sniffing out the one weird little side quest about the mundan‚Ä¶', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'PepperoniDeluxe', 'name': 'Dick Jarvis', 'id': 605978230, 'id_str': '605978230', 'indices': [3, 19]}], 'urls': []}, 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'retweeted_status': {'created_at': 'Mon May 25 19:47:02 +0000 2020', 'id': 1265006482929704967, 'id_str': '1265006482929704967', 'text': 'You guys went through my fantasy city like truffle pigs, sniffing out the one weird little side quest about the mun‚Ä¶ https://t.co/27YPV9pndJ', 'truncated': True, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/27YPV9pndJ', 'expanded_url': 'https://twitter.com/i/web/status/1265006482929704967', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [117, 140]}]}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': True, 'quoted_status_id': 1264993763551739904, 'quoted_status_id_str': '1264993763551739904', 'retweet_count': 1, 'favorite_count': 16, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'is_quote_status': True, 'quoted_status_id': 1264993763551739904, 'quoted_status_id_str': '1264993763551739904', 'retweet_count': 1, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1117241109485367296/WuLSGFNk_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1117241109485367296/WuLSGFNk_normal.png', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/2809015377/1555206645', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 293651076, 'id_str': '293651076', 'name': 'James Wasmuth', 'screen_name': 'jdwasmuth', 'location': 'Calgary', 'description': 'Head of @TheGradCollege. Assoc. Prof. @ucalgaryvetmed.\\nPathogen Genomics. Tea addict. Tweets my own.\\nPronouns: he/him/his.', 'url': 'https://t.co/Eo6IxEsCIe', 'entities': {'url': {'urls': [{'url': 'https://t.co/Eo6IxEsCIe', 'expanded_url': 'http://wasmuthlab.org', 'display_url': 'wasmuthlab.org', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 1063, 'friends_count': 1041, 'listed_count': 34, 'created_at': 'Thu May 05 18:40:15 +0000 2011', 'favourites_count': 1355, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 9476, 'lang': None, 'status': {'created_at': 'Wed May 27 16:40:49 +0000 2020', 'id': 1265684393244254208, 'id_str': '1265684393244254208', 'text': 'RT @barbcarra: This is a great visualization of how our Canadian National Research &amp; Education network is more than just network infrastruc‚Ä¶', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'barbcarra', 'name': 'Barb Carra', 'id': 119935760, 'id_str': '119935760', 'indices': [3, 13]}], 'urls': []}, 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'retweeted_status': {'created_at': 'Wed May 27 16:35:57 +0000 2020', 'id': 1265683170449473536, 'id_str': '1265683170449473536', 'text': 'This is a great visualization of how our Canadian National Research &amp; Education network is more than just network i‚Ä¶ https://t.co/FUSrLpJ51y', 'truncated': True, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/FUSrLpJ51y', 'expanded_url': 'https://twitter.com/i/web/status/1265683170449473536', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [121, 144]}]}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': {'id': '53504716d445dcad', 'url': 'https://api.twitter.com/1.1/geo/id/53504716d445dcad.json', 'place_type': 'city', 'name': 'Calgary', 'full_name': 'Calgary, Alberta', 'country_code': 'CA', 'country': 'Canada', 'contained_within': [], 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-114.3160379, 50.84278], [-113.859664, 50.84278], [-113.859664, 51.212548], [-114.3160379, 51.212548]]]}, 'attributes': {}}, 'contributors': None, 'is_quote_status': True, 'quoted_status_id': 1265680420215099392, 'quoted_status_id_str': '1265680420215099392', 'retweet_count': 3, 'favorite_count': 2, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'is_quote_status': True, 'quoted_status_id': 1265680420215099392, 'quoted_status_id_str': '1265680420215099392', 'retweet_count': 3, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '200709', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/897326854041812992/jpcYudY4_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/897326854041812992/jpcYudY4_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/293651076/1369630040', 'profile_link_color': '6A4836', 'profile_sidebar_border_color': 'B68B9E', 'profile_sidebar_fill_color': '200709', 'profile_text_color': 'C96D43', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 743086431971778561, 'id_str': '743086431971778561', 'name': 'The Archives Unleashed Project', 'screen_name': 'unleasharchives', 'location': 'Waterloo, Ontario; Toronto, Ontario', 'description': 'Our goal is to make petabytes of historical internet content accessible to scholars and others interested in researching the recent past.', 'url': 'https://t.co/BxjXShhjOm', 'entities': {'url': {'urls': [{'url': 'https://t.co/BxjXShhjOm', 'expanded_url': 'http://archivesunleashed.org', 'display_url': 'archivesunleashed.org', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 964, 'friends_count': 393, 'listed_count': 44, 'created_at': 'Wed Jun 15 14:23:06 +0000 2016', 'favourites_count': 346, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 373, 'lang': None, 'status': {'created_at': 'Wed May 27 13:10:14 +0000 2020', 'id': 1265631400469856257, 'id_str': '1265631400469856257', 'text': 'RT @NetPreserve: \"Collecting so that we don‚Äôt forget\" &amp; \"Focus on collaborative networks\" - 2 blog posts on the #COVID19 #webarchive collec‚Ä¶', 'truncated': False, 'entities': {'hashtags': [{'text': 'COVID19', 'indices': [116, 124]}, {'text': 'webarchive', 'indices': [125, 136]}], 'symbols': [], 'user_mentions': [{'screen_name': 'NetPreserve', 'name': 'IIPC', 'id': 259850415, 'id_str': '259850415', 'indices': [3, 15]}], 'urls': []}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'retweeted_status': {'created_at': 'Wed May 27 12:47:07 +0000 2020', 'id': 1265625581745573889, 'id_str': '1265625581745573889', 'text': '\"Collecting so that we don‚Äôt forget\" &amp; \"Focus on collaborative networks\" - 2 blog posts on the #COVID19 #webarchive‚Ä¶ https://t.co/f5PLwq7gN9', 'truncated': True, 'entities': {'hashtags': [{'text': 'COVID19', 'indices': [99, 107]}, {'text': 'webarchive', 'indices': [108, 119]}], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/f5PLwq7gN9', 'expanded_url': 'https://twitter.com/i/web/status/1265625581745573889', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [121, 144]}]}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 9, 'favorite_count': 12, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'is_quote_status': False, 'retweet_count': 9, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/930612789542080512/DDkyO79n_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/930612789542080512/DDkyO79n_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/743086431971778561/1510671188', 'profile_link_color': '1B95E0', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 154793244, 'id_str': '154793244', 'name': 'Andy Teucher', 'screen_name': 'andyteucher', 'location': 'Victoria, BC', 'description': 'Enviro Data Science & #rstats/#rspatial. Open Data, Open Gov. Some football (the round kind), mostly #CanWNT & #CanMNT. Fueled by craft beer & good coffee.', 'url': 'https://t.co/z81er97Ci7', 'entities': {'url': {'urls': [{'url': 'https://t.co/z81er97Ci7', 'expanded_url': 'http://github.com/ateucher', 'display_url': 'github.com/ateucher', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 567, 'friends_count': 894, 'listed_count': 59, 'created_at': 'Sat Jun 12 06:09:56 +0000 2010', 'favourites_count': 2692, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 4497, 'lang': None, 'status': {'created_at': 'Tue May 26 22:00:53 +0000 2020', 'id': 1265402554029969408, 'id_str': '1265402554029969408', 'text': 'RT @JoshuaPotash: This is Christian Cooper. https://t.co/gOQyVztX5h', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'JoshuaPotash', 'name': 'Joshua Potash', 'id': 1090715513586679813, 'id_str': '1090715513586679813', 'indices': [3, 16]}], 'urls': [], 'media': [{'id': 1265337859067858947, 'id_str': '1265337859067858947', 'indices': [44, 67], 'media_url': 'http://pbs.twimg.com/ext_tw_video_thumb/1265337859067858947/pu/img/_v7XYBcNX4CsYiMe.jpg', 'media_url_https': 'https://pbs.twimg.com/ext_tw_video_thumb/1265337859067858947/pu/img/_v7XYBcNX4CsYiMe.jpg', 'url': 'https://t.co/gOQyVztX5h', 'display_url': 'pic.twitter.com/gOQyVztX5h', 'expanded_url': 'https://twitter.com/JoshuaPotash/status/1265338098256424973/video/1', 'type': 'photo', 'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'medium': {'w': 1200, 'h': 675, 'resize': 'fit'}, 'small': {'w': 680, 'h': 383, 'resize': 'fit'}, 'large': {'w': 1280, 'h': 720, 'resize': 'fit'}}, 'source_status_id': 1265338098256424973, 'source_status_id_str': '1265338098256424973', 'source_user_id': 1090715513586679813, 'source_user_id_str': '1090715513586679813'}]}, 'extended_entities': {'media': [{'id': 1265337859067858947, 'id_str': '1265337859067858947', 'indices': [44, 67], 'media_url': 'http://pbs.twimg.com/ext_tw_video_thumb/1265337859067858947/pu/img/_v7XYBcNX4CsYiMe.jpg', 'media_url_https': 'https://pbs.twimg.com/ext_tw_video_thumb/1265337859067858947/pu/img/_v7XYBcNX4CsYiMe.jpg', 'url': 'https://t.co/gOQyVztX5h', 'display_url': 'pic.twitter.com/gOQyVztX5h', 'expanded_url': 'https://twitter.com/JoshuaPotash/status/1265338098256424973/video/1', 'type': 'video', 'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'medium': {'w': 1200, 'h': 675, 'resize': 'fit'}, 'small': {'w': 680, 'h': 383, 'resize': 'fit'}, 'large': {'w': 1280, 'h': 720, 'resize': 'fit'}}, 'source_status_id': 1265338098256424973, 'source_status_id_str': '1265338098256424973', 'source_user_id': 1090715513586679813, 'source_user_id_str': '1090715513586679813', 'video_info': {'aspect_ratio': [16, 9], 'duration_millis': 17697, 'variants': [{'bitrate': 256000, 'content_type': 'video/mp4', 'url': 'https://video.twimg.com/ext_tw_video/1265337859067858947/pu/vid/480x270/KY4DPfqmSfZcfscG.mp4?tag=11'}, {'content_type': 'application/x-mpegURL', 'url': 'https://video.twimg.com/ext_tw_video/1265337859067858947/pu/pl/OJe3q9tHL5Yhndm-.m3u8?tag=11'}, {'bitrate': 832000, 'content_type': 'video/mp4', 'url': 'https://video.twimg.com/ext_tw_video/1265337859067858947/pu/vid/640x360/U2QQ9OxyZSeVTIL9.mp4?tag=11'}]}, 'additional_media_info': {'monetizable': False}}]}, 'source': '<a href=\"https://twitterrific.com/ios\" rel=\"nofollow\">Twitterrific for iOS</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'retweeted_status': {'created_at': 'Tue May 26 17:44:46 +0000 2020', 'id': 1265338098256424973, 'id_str': '1265338098256424973', 'text': 'This is Christian Cooper. https://t.co/gOQyVztX5h', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [], 'media': [{'id': 1265337859067858947, 'id_str': '1265337859067858947', 'indices': [26, 49], 'media_url': 'http://pbs.twimg.com/ext_tw_video_thumb/1265337859067858947/pu/img/_v7XYBcNX4CsYiMe.jpg', 'media_url_https': 'https://pbs.twimg.com/ext_tw_video_thumb/1265337859067858947/pu/img/_v7XYBcNX4CsYiMe.jpg', 'url': 'https://t.co/gOQyVztX5h', 'display_url': 'pic.twitter.com/gOQyVztX5h', 'expanded_url': 'https://twitter.com/JoshuaPotash/status/1265338098256424973/video/1', 'type': 'photo', 'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'medium': {'w': 1200, 'h': 675, 'resize': 'fit'}, 'small': {'w': 680, 'h': 383, 'resize': 'fit'}, 'large': {'w': 1280, 'h': 720, 'resize': 'fit'}}}]}, 'extended_entities': {'media': [{'id': 1265337859067858947, 'id_str': '1265337859067858947', 'indices': [26, 49], 'media_url': 'http://pbs.twimg.com/ext_tw_video_thumb/1265337859067858947/pu/img/_v7XYBcNX4CsYiMe.jpg', 'media_url_https': 'https://pbs.twimg.com/ext_tw_video_thumb/1265337859067858947/pu/img/_v7XYBcNX4CsYiMe.jpg', 'url': 'https://t.co/gOQyVztX5h', 'display_url': 'pic.twitter.com/gOQyVztX5h', 'expanded_url': 'https://twitter.com/JoshuaPotash/status/1265338098256424973/video/1', 'type': 'video', 'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'medium': {'w': 1200, 'h': 675, 'resize': 'fit'}, 'small': {'w': 680, 'h': 383, 'resize': 'fit'}, 'large': {'w': 1280, 'h': 720, 'resize': 'fit'}}, 'video_info': {'aspect_ratio': [16, 9], 'duration_millis': 17697, 'variants': [{'bitrate': 256000, 'content_type': 'video/mp4', 'url': 'https://video.twimg.com/ext_tw_video/1265337859067858947/pu/vid/480x270/KY4DPfqmSfZcfscG.mp4?tag=11'}, {'content_type': 'application/x-mpegURL', 'url': 'https://video.twimg.com/ext_tw_video/1265337859067858947/pu/pl/OJe3q9tHL5Yhndm-.m3u8?tag=11'}, {'bitrate': 832000, 'content_type': 'video/mp4', 'url': 'https://video.twimg.com/ext_tw_video/1265337859067858947/pu/vid/640x360/U2QQ9OxyZSeVTIL9.mp4?tag=11'}]}, 'additional_media_info': {'monetizable': False}}]}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 30427, 'favorite_count': 166812, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'is_quote_status': False, 'retweet_count': 30427, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'B2DFDA', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme13/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme13/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/509021766979579904/lAjlpu7x_normal.jpeg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/509021766979579904/lAjlpu7x_normal.jpeg', 'profile_link_color': '93A644', 'profile_sidebar_border_color': 'EEEEEE', 'profile_sidebar_fill_color': 'FFFFFF', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 468571696, 'id_str': '468571696', 'name': 'zero', 'screen_name': 'sabari_88999', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': True, 'followers_count': 119, 'friends_count': 4909, 'listed_count': 2, 'created_at': 'Thu Jan 19 17:43:45 +0000 2012', 'favourites_count': 6614, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 1871, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1153532657642295297/_gf0izpl_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1153532657642295297/_gf0izpl_normal.jpg', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 1155634482629791746, 'id_str': '1155634482629791746', 'name': 'Applied Machine Learning', 'screen_name': 'USE_ML', 'location': '', 'description': 'Applied Machine Learning aims to showcase the interesting use cases for machine learning technology across various industries.', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 1515, 'friends_count': 4954, 'listed_count': 7, 'created_at': 'Mon Jul 29 00:21:46 +0000 2019', 'favourites_count': 263, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 313, 'lang': None, 'status': {'created_at': 'Sun May 24 14:08:52 +0000 2020', 'id': 1264558992195543041, 'id_str': '1264558992195543041', 'text': 'Time to learn some basics? https://t.co/kBT2e6oraC', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/kBT2e6oraC', 'expanded_url': 'https://youtu.be/dlLHN7rL03w', 'display_url': 'youtu.be/dlLHN7rL03w', 'indices': [27, 50]}]}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 1, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1156219969778012160/eNgQreFi_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1156219969778012160/eNgQreFi_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1155634482629791746/1564499758', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 59819048, 'id_str': '59819048', 'name': 'Seth Frey', 'screen_name': 'enfascination', 'location': 'Davis, CA', 'description': 'social + computational + cognitive scientist in academia.\\nscience of self-governance, online and offline.\\nscience towards nescience.', 'url': 'http://t.co/XOZhlghoiN', 'entities': {'url': {'urls': [{'url': 'http://t.co/XOZhlghoiN', 'expanded_url': 'http://enfascination.com', 'display_url': 'enfascination.com', 'indices': [0, 22]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 397, 'friends_count': 261, 'listed_count': 12, 'created_at': 'Fri Jul 24 16:09:18 +0000 2009', 'favourites_count': 77, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 439, 'lang': None, 'status': {'created_at': 'Wed May 27 17:13:02 +0000 2020', 'id': 1265692501618257926, 'id_str': '1265692501618257926', 'text': 'been getting into theory.  Fun perspectives: \"Democracy is distinguished by its capacities to move the contested in‚Ä¶ https://t.co/rqSgrUSXaw', 'truncated': True, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/rqSgrUSXaw', 'expanded_url': 'https://twitter.com/i/web/status/1265692501618257926', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [117, 140]}]}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/330115112/critch4_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/330115112/critch4_normal.jpg', 'profile_link_color': '0F96ED', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 14726818, 'id_str': '14726818', 'name': 'cdfelker', 'screen_name': 'cdfelker', 'location': 'San Francisco CA', 'description': 'Notable stuff from a progressive California hub.', 'url': 'https://t.co/JXnYMIWKAR', 'entities': {'url': {'urls': [{'url': 'https://t.co/JXnYMIWKAR', 'expanded_url': 'http://open.spotify.com/user/cfelker', 'display_url': 'open.spotify.com/user/cfelker', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': True, 'followers_count': 73, 'friends_count': 1410, 'listed_count': 0, 'created_at': 'Sat May 10 18:42:59 +0000 2008', 'favourites_count': 89, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 723, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/751134687779696640/Ihi8qQn__normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/751134687779696640/Ihi8qQn__normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/14726818/1400793069', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 1468480220, 'id_str': '1468480220', 'name': 'alessio baldini', 'screen_name': 'ab_alessio', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 51, 'friends_count': 98, 'listed_count': 0, 'created_at': 'Wed May 29 23:25:30 +0000 2013', 'favourites_count': 0, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 13, 'lang': None, 'status': {'created_at': 'Tue Apr 21 04:56:41 +0000 2020', 'id': 1252461230331133952, 'id_str': '1252461230331133952', 'text': 'Universities are pleading for a bailout to paper over their failures https://t.co/CNcSrp5dpk via @financialtimes', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'FinancialTimes', 'name': 'Financial Times', 'id': 4898091, 'id_str': '4898091', 'indices': [97, 112]}], 'urls': [{'url': 'https://t.co/CNcSrp5dpk', 'expanded_url': 'https://www.ft.com/content/7be4f44e-7582-11ea-95fe-fcd274e920ca', 'display_url': 'ft.com/content/7be4f4‚Ä¶', 'indices': [69, 92]}]}, 'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 2, 'favorite_count': 2, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '1A1B1F', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/426866801838788609/i5pVaaOJ_normal.jpeg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/426866801838788609/i5pVaaOJ_normal.jpeg', 'profile_link_color': '2FC2EF', 'profile_sidebar_border_color': 'FFFFFF', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 2831073533, 'id_str': '2831073533', 'name': 'Andr√©s Beita', 'screen_name': 'abeitaj', 'location': \"St. John's, Newfoundland and L\", 'description': 'Costa Rican biologist, fisheries stock assessment graduate student at @marineinstitute. Study #Fisheries #statistics #rstats. @thecarpentries instructor', 'url': 'https://t.co/K20x6GRzaq', 'entities': {'url': {'urls': [{'url': 'https://t.co/K20x6GRzaq', 'expanded_url': 'https://andresbeita.github.io/', 'display_url': 'andresbeita.github.io', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 218, 'friends_count': 895, 'listed_count': 2, 'created_at': 'Wed Oct 15 04:07:47 +0000 2014', 'favourites_count': 1438, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 308, 'lang': None, 'status': {'created_at': 'Tue Mar 10 15:00:44 +0000 2020', 'id': 1237392955473719298, 'id_str': '1237392955473719298', 'text': 'RT @Rovingdiver2: Anyone ready to postdoc and analyze global reef fish relative abundance trends (immediately)? Just your semi regular remi‚Ä¶', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'Rovingdiver2', 'name': 'Brice semmens', 'id': 232607946, 'id_str': '232607946', 'indices': [3, 16]}], 'urls': []}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'retweeted_status': {'created_at': 'Mon Mar 09 23:10:10 +0000 2020', 'id': 1237153734754332672, 'id_str': '1237153734754332672', 'text': 'Anyone ready to postdoc and analyze global reef fish relative abundance trends (immediately)? Just your semi regula‚Ä¶ https://t.co/0untANTtb1', 'truncated': True, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/0untANTtb1', 'expanded_url': 'https://twitter.com/i/web/status/1237153734754332672', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [117, 140]}]}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 116, 'favorite_count': 102, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'is_quote_status': False, 'retweet_count': 116, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/610676416368087040/Gi3TTfVs_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/610676416368087040/Gi3TTfVs_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/2831073533/1418748461', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 326077427, 'id_str': '326077427', 'name': 'Danielle Quinn (she/her)', 'screen_name': 'daniellequinn88', 'location': 'Newfoundland and Labrador', 'description': '#rstats #ecoinformatics #marinebio #womeninSTEM | @RStudio instructor, @TheCarpentries instructor/trainer, @terranautclub pres., @MemorialU PhD cand.', 'url': 'https://t.co/KAgrW7ljJw', 'entities': {'url': {'urls': [{'url': 'https://t.co/KAgrW7ljJw', 'expanded_url': 'https://www.daniellequinn.org/', 'display_url': 'daniellequinn.org', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 1252, 'friends_count': 1477, 'listed_count': 30, 'created_at': 'Wed Jun 29 10:15:17 +0000 2011', 'favourites_count': 8245, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 2795, 'lang': None, 'status': {'created_at': 'Tue May 26 01:10:13 +0000 2020', 'id': 1265087813017579521, 'id_str': '1265087813017579521', 'text': '@medburnbook Inches and centimeters, mixed, unlabelled.', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'medburnbook', 'name': 'status annoyicus', 'id': 1216464474930130945, 'id_str': '1216464474930130945', 'indices': [0, 12]}], 'urls': []}, 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', 'in_reply_to_status_id': 1263677983199461376, 'in_reply_to_status_id_str': '1263677983199461376', 'in_reply_to_user_id': 1216464474930130945, 'in_reply_to_user_id_str': '1216464474930130945', 'in_reply_to_screen_name': 'medburnbook', 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 5, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme3/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme3/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1231058965221584901/B4mIm47-_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1231058965221584901/B4mIm47-_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/326077427/1581137118', 'profile_link_color': '2D0824', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': True, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 7465672, 'id_str': '7465672', 'name': 'Quinn Dombrowski', 'screen_name': 'quinnanya', 'location': 'Berkeley, CA', 'description': 'Non-English digital humanities at Stanford. Fond of medieval Slavic, infrastructure, and honest reflections on failure. Non-binary, any pronouns are fine.', 'url': 'http://t.co/zNUB2jry9F', 'entities': {'url': {'urls': [{'url': 'http://t.co/zNUB2jry9F', 'expanded_url': 'http://www.quinndombrowski.com', 'display_url': 'quinndombrowski.com', 'indices': [0, 22]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 2827, 'friends_count': 1303, 'listed_count': 89, 'created_at': 'Sat Jul 14 04:30:03 +0000 2007', 'favourites_count': 13366, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 7823, 'lang': None, 'status': {'created_at': 'Wed May 27 16:28:43 +0000 2020', 'id': 1265681347802103808, 'id_str': '1265681347802103808', 'text': \"@cecilealduy That's a lovely idea! (I wonder if I can find a Baby-Sitters Club cover to correspond to it for another day...)\", 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'cecilealduy', 'name': 'cecile alduy', 'id': 168892482, 'id_str': '168892482', 'indices': [0, 12]}], 'urls': []}, 'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>', 'in_reply_to_status_id': 1265668760226033664, 'in_reply_to_status_id_str': '1265668760226033664', 'in_reply_to_user_id': 168892482, 'in_reply_to_user_id_str': '168892482', 'in_reply_to_screen_name': 'cecilealduy', 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'ACDED6', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme18/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme18/bg.gif', 'profile_background_tile': True, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1265069510316318721/w78jvJ4u_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1265069510316318721/w78jvJ4u_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/7465672/1536969063', 'profile_link_color': '038543', 'profile_sidebar_border_color': 'FFFFFF', 'profile_sidebar_fill_color': 'F6F6F6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': True, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 1142871446, 'id_str': '1142871446', 'name': 'Dr. Anelise Hanson Shrout', 'screen_name': 'AneliseHShrout', 'location': '', 'description': 'Digital Historian. #DH & #Quant approaches to #Atlantic, #19thc & #VastEarlyAmerica. From NJ. Working in ME on occupied Wabanaki land. Opinions mine. She/her.', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 1927, 'friends_count': 2814, 'listed_count': 63, 'created_at': 'Sat Feb 02 16:41:40 +0000 2013', 'favourites_count': 5557, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 7762, 'lang': None, 'status': {'created_at': 'Wed May 27 14:13:36 +0000 2020', 'id': 1265647346315956226, 'id_str': '1265647346315956226', 'text': \"@llchristyll @historianess @Jamaicanhist @nyuniversity Same here - with no indication if they'll ever come back.\", 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'llchristyll', 'name': 'Christy Thornton', 'id': 239884649, 'id_str': '239884649', 'indices': [0, 12]}, {'screen_name': 'historianess', 'name': 'Doctor Historianess üêçüêçüêç', 'id': 140665322, 'id_str': '140665322', 'indices': [13, 26]}, {'screen_name': 'Jamaicanhist', 'name': 'Brooke Newman', 'id': 785537265057488896, 'id_str': '785537265057488896', 'indices': [27, 40]}, {'screen_name': 'nyuniversity', 'name': 'New York University', 'id': 28421825, 'id_str': '28421825', 'indices': [41, 54]}], 'urls': []}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': 1265645757438230531, 'in_reply_to_status_id_str': '1265645757438230531', 'in_reply_to_user_id': 239884649, 'in_reply_to_user_id_str': '239884649', 'in_reply_to_screen_name': 'llchristyll', 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 3, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '709397', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme6/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme6/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1166525399075053569/P18uvdXf_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1166525399075053569/P18uvdXf_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1142871446/1554908086', 'profile_link_color': 'FF3300', 'profile_sidebar_border_color': '86A4A6', 'profile_sidebar_fill_color': 'A0C5C7', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 15280441, 'id_str': '15280441', 'name': 'Martin Jean', 'screen_name': 'botanyman', 'location': 'Sud du Qu√©bec', 'description': \"Scientifique fonctionnaire, conjoint, p√®re, environnement, technologie, design, photographie, science ouverte. Mes propos n'engagent que moi.\", 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 208, 'friends_count': 387, 'listed_count': 17, 'created_at': 'Mon Jun 30 16:56:52 +0000 2008', 'favourites_count': 183, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 688, 'lang': None, 'status': {'created_at': 'Thu May 07 20:11:52 +0000 2020', 'id': 1258489750492758022, 'id_str': '1258489750492758022', 'text': \"RT @Boucherville_: COVID-19 | 7 mai 2020\\nLe maire Jean Martel fait le point sur l'√©tat de la situation √† Boucherville. https://t.co/WHSCLh7‚Ä¶\", 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'Boucherville_', 'name': 'VilledeBoucherville', 'id': 77291170, 'id_str': '77291170', 'indices': [3, 17]}], 'urls': []}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'retweeted_status': {'created_at': 'Thu May 07 20:11:23 +0000 2020', 'id': 1258489628627218433, 'id_str': '1258489628627218433', 'text': \"COVID-19 | 7 mai 2020\\nLe maire Jean Martel fait le point sur l'√©tat de la situation √† Boucherville. https://t.co/WHSCLh7UaV\", 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/WHSCLh7UaV', 'expanded_url': 'https://vimeo.com/416053538', 'display_url': 'vimeo.com/416053538', 'indices': [100, 123]}]}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 1, 'favorite_count': 1, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'fr'}, 'is_quote_status': False, 'retweet_count': 1, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'fr'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '352726', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme5/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme5/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/733987663561232384/p_0qTDzd_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/733987663561232384/p_0qTDzd_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/15280441/1463911341', 'profile_link_color': 'D02B55', 'profile_sidebar_border_color': '829D5E', 'profile_sidebar_fill_color': '99CC33', 'profile_text_color': '3E4415', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 108797530, 'id_str': '108797530', 'name': 'Diane Kelly-Riley', 'screen_name': 'dianekellyriley', 'location': 'Idaho', 'description': 'Idaho. Fiddler. Flyfisher. Author/Editor of Improving Outcomes: Disciplinary Writing, Local Assessment and the Aim of Fairness. Forthcoming from MLA in 2020.', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 402, 'friends_count': 1712, 'listed_count': 11, 'created_at': 'Wed Jan 27 02:08:59 +0000 2010', 'favourites_count': 13118, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 2523, 'lang': None, 'status': {'created_at': 'Wed May 27 04:08:00 +0000 2020', 'id': 1265494943583346688, 'id_str': '1265494943583346688', 'text': '@etkeld Agreed!!!!', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'etkeld', 'name': 'Eric Kelderman', 'id': 7857542, 'id_str': '7857542', 'indices': [0, 7]}], 'urls': []}, 'source': '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>', 'in_reply_to_status_id': 1265478443522830336, 'in_reply_to_status_id_str': '1265478443522830336', 'in_reply_to_user_id': 7857542, 'in_reply_to_user_id_str': '7857542', 'in_reply_to_screen_name': 'etkeld', 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C6E2EE', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme2/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme2/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/987508972612567040/4QQXljTi_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/987508972612567040/4QQXljTi_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/108797530/1490494652', 'profile_link_color': '1F98C7', 'profile_sidebar_border_color': 'C6E2EE', 'profile_sidebar_fill_color': 'DAECF4', 'profile_text_color': '663B12', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 3280014502, 'id_str': '3280014502', 'name': 'Áå¥Â≠ê', 'screen_name': 'hou2zi0', 'location': 'Mainz, Rheinland-Pfalz', 'description': 'History, Philosophy & Digital Humanities @digicademy', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 739, 'friends_count': 2308, 'listed_count': 94, 'created_at': 'Sun May 17 18:58:39 +0000 2015', 'favourites_count': 15985, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 29960, 'lang': None, 'status': {'created_at': 'Sun Nov 03 20:58:29 +0000 2019', 'id': 1191097338686779392, 'id_str': '1191097338686779392', 'text': 'RT @reinboth: In #Trautenstein im #Harz hat man \"aus zeitgeschichtlichen Erw√§gungen\" das w√§hrend der NS-Zeit errichtete Dorfgemeinschaftsha‚Ä¶', 'truncated': False, 'entities': {'hashtags': [{'text': 'Trautenstein', 'indices': [17, 30]}, {'text': 'Harz', 'indices': [34, 39]}], 'symbols': [], 'user_mentions': [{'screen_name': 'reinboth', 'name': 'Christian Reinboth', 'id': 17187345, 'id_str': '17187345', 'indices': [3, 12]}], 'urls': []}, 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'retweeted_status': {'created_at': 'Sun Nov 03 18:42:38 +0000 2019', 'id': 1191063149979557888, 'id_str': '1191063149979557888', 'text': 'In #Trautenstein im #Harz hat man \"aus zeitgeschichtlichen Erw√§gungen\" das w√§hrend der NS-Zeit errichtete Dorfgemei‚Ä¶ https://t.co/Ba4yhEuqnh', 'truncated': True, 'entities': {'hashtags': [{'text': 'Trautenstein', 'indices': [3, 16]}, {'text': 'Harz', 'indices': [20, 25]}], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/Ba4yhEuqnh', 'expanded_url': 'https://twitter.com/i/web/status/1191063149979557888', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [117, 140]}]}, 'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 205, 'favorite_count': 167, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'de'}, 'is_quote_status': False, 'retweet_count': 205, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'de'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/600276057896390656/gDBmEafP_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/600276057896390656/gDBmEafP_normal.jpg', 'profile_link_color': 'DD2E44', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 1281391231, 'id_str': '1281391231', 'name': 'Kristen D Highland', 'screen_name': 'kdhighland', 'location': 'Sharjah, United Arab Emirates', 'description': 'Asst Prof of English at American University of Sharjah, UAE | Early Americana | bookstores | spatial and digital humanities', 'url': 'https://t.co/1MzRjIohGI', 'entities': {'url': {'urls': [{'url': 'https://t.co/1MzRjIohGI', 'expanded_url': 'http://kristendoylehighland.com', 'display_url': 'kristendoylehighland.com', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 526, 'friends_count': 1243, 'listed_count': 19, 'created_at': 'Tue Mar 19 20:01:42 +0000 2013', 'favourites_count': 2518, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 932, 'lang': None, 'status': {'created_at': 'Fri May 22 21:11:02 +0000 2020', 'id': 1263940455840075778, 'id_str': '1263940455840075778', 'text': 'RT @dorothyk98: A 48-hour Shakespeare readathon is happening this weekend to help save the Globe theatre | https://t.co/wv9Gu0ssl7', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'dorothyk98', 'name': 'Dr. Dorothy Kim', 'id': 555984374, 'id_str': '555984374', 'indices': [3, 14]}], 'urls': [{'url': 'https://t.co/wv9Gu0ssl7', 'expanded_url': 'https://www.timeout.com/london/news/a-48-hour-shakespeare-readathon-is-happening-this-weekend-to-help-save-the-globe-theatre-052220', 'display_url': 'timeout.com/london/news/a-‚Ä¶', 'indices': [107, 130]}]}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'retweeted_status': {'created_at': 'Fri May 22 20:35:23 +0000 2020', 'id': 1263931484441886726, 'id_str': '1263931484441886726', 'text': 'A 48-hour Shakespeare readathon is happening this weekend to help save the Globe theatre | https://t.co/wv9Gu0ssl7', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/wv9Gu0ssl7', 'expanded_url': 'https://www.timeout.com/london/news/a-48-hour-shakespeare-readathon-is-happening-this-weekend-to-help-save-the-globe-theatre-052220', 'display_url': 'timeout.com/london/news/a-‚Ä¶', 'indices': [91, 114]}]}, 'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 10, 'favorite_count': 7, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'is_quote_status': False, 'retweet_count': 10, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'EBEBEB', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme7/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme7/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1123619330279792642/qtTZ8wpf_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1123619330279792642/qtTZ8wpf_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1281391231/1554310507', 'profile_link_color': '990000', 'profile_sidebar_border_color': 'DFDFDF', 'profile_sidebar_fill_color': 'F3F3F3', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n",
      "{'id': 20655405, 'id_str': '20655405', 'name': 'Sydney Lines', 'screen_name': 'SydneyALines', 'location': 'Vancouver, British Columbia', 'description': 'PhD student @ubc_english | C18/19 Norse Britain, Race & Nationalism | Museums, #DH & Public Culture. Feminist cat lady. 1st gen. Settler scholar. She/her.', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 253, 'friends_count': 786, 'listed_count': 8, 'created_at': 'Thu Feb 12 04:58:16 +0000 2009', 'favourites_count': 3869, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 4070, 'lang': None, 'status': {'created_at': 'Sat May 23 04:33:07 +0000 2020', 'id': 1264051713046016000, 'id_str': '1264051713046016000', 'text': 'RT @staceyNYCDC: This woman shutdown her business and laid off her 13 employees because her husband said he couldn‚Äôt handle being the prima‚Ä¶', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'staceyNYCDC', 'name': 'Stacey E. Singleton', 'id': 452568163, 'id_str': '452568163', 'indices': [3, 15]}], 'urls': []}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'retweeted_status': {'created_at': 'Sat May 23 01:30:03 +0000 2020', 'id': 1264005641867276300, 'id_str': '1264005641867276300', 'text': 'This woman shutdown her business and laid off her 13 employees because her husband said he couldn‚Äôt handle being th‚Ä¶ https://t.co/aJGJ4Uz7Fp', 'truncated': True, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/aJGJ4Uz7Fp', 'expanded_url': 'https://twitter.com/i/web/status/1264005641867276300', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [117, 140]}]}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 11315, 'favorite_count': 44509, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'is_quote_status': False, 'retweet_count': 11315, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1244096605860401152/dsUlTdik_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1244096605860401152/dsUlTdik_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/20655405/1578941622', 'profile_link_color': '19CF86', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': True, 'default_profile': False, 'default_profile_image': False, 'following': False, 'live_following': False, 'follow_request_sent': False, 'notifications': False, 'muting': False, 'blocking': False, 'blocked_by': False, 'translator_type': 'none'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "TwitterHandle = 'symulation'\n",
    "\n",
    "r = api.request('followers/list', {'screen_name': TwitterHandle})\n",
    "\n",
    "for item in r.get_iterator():\n",
    "    print(item,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two approaches to collecting information from Twitter: grabbing tweets as they are published and searching through the archive of past tweets.  The first approach is known as \"streaming\" and we'll look at how to use it now (The second we'll call \"standard search\" and we'll look at it next).  It is important to note up front that the results returned using this method are incomplete: you will _not_ necessarily capture every single tweet that you intend to this way.  Still, you can get a lot of tweets in a very short time and likely enough to get you started (assuming your search terms are not overly restrictive).\n",
    "\n",
    "Streaming amounts to applying a set of filters to the stream of all tweets being published from now until we stop reading the stream and capturing what is matched by those filters.  For this first example we'll simply print the body of each tweet out on the screen.  There are lots of opinions about Donald Trump right now so we'll use 'trump' as the term we are tracking.\n",
    "\n",
    "!!! IMPORTANT !!!\n",
    "\n",
    "When streaming it is possible for your code to run indefinitely.  In the case of the cell below you'll want to stop it at some point‚Äîlikely after only a few seconds!‚Äîso be prepared to click the stop button at the top of this workbook once you have some tweets in the output cell.  If you leave the search term as 'trump' then you'll have enough tweets to prove that it works after about two seconds!\n",
    "\n",
    "It is also possible that you'll hit a rate limit with the search term \"trump\".  If you approach a 1% sample of all the tweets being published with your request then the API will cut you off.  This will look like a \"key error\" because the code is looking for the key \"text\" in the JSON that is returned but it's not finding it because the API didn't give any text as a response. \n",
    "\n",
    "Lastly, note that the API only returns tweets inside a 10ms window per second.  You will not be getting everything via streaming.\n",
    "\n",
    "!!! IMPORTANT !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1839\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[0;34m(self, ssl, result)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a5d407a47fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'statuses/filter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTRACK_TERM\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'text'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/TwitterAPI/TwitterAPI.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mraises\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTwitterConnectionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/TwitterAPI/TwitterAPI.py\u001b[0m in \u001b[0;36m_iter_stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0;31m# read bytes until item boundary reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                     \u001b[0mbuf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                         \u001b[0;31m# check for stall (i.e. no data for 90 seconds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m                 if (\n\u001b[1;32m    509\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The read operation timed out\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mwait_for_read\u001b[0;34m(sock, timeout)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msocket\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0mexpired\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \"\"\"\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwait_for_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mpoll_wait_for_socket\u001b[0;34m(sock, read, write, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpoll_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_retry_on_intr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_poll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36m_retry_on_intr\u001b[0;34m(fn, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Modern Python, that retries syscalls by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_retry_on_intr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mdo_poll\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpoll_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_retry_on_intr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_poll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRACK_TERM = 'covid daycare'\n",
    "\n",
    "r = api.request('statuses/filter', {'track': TRACK_TERM})\n",
    "\n",
    "for item in r.get_iterator():\n",
    "    print(item['text'],item['id'] if 'text' in item else item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value passed to TRACK_TERM can be modified as per the standard search operators (or the premium ones once we get there) defined by the Twitter API to filer what is returned.  You can see a list of all the standard operators with examples [HERE](https://developer.twitter.com/en/docs/tweets/rules-and-filtering/overview/standard-operators)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As satisfying as it may be to have an endless stream of tweets scroll in front of you there isn't much value in it unless you are able to capture the tweets for analysis in the future. If you really only need a few and only need them once then you can just cut and copy from the output above.  In most cases though you'll want a lot of tweets or want to collect them multiple times.  In such cases the ideal thing to do is write the tweets to a database because then you will have the search features of the database at your disposal.  We'll get to interacting with database later in this workbook but keep in mind that actually setting up that database is beyond the scope of this workbook (If you're not sure where to start, [MongoDB](https://www.mongodb.com/) is worth considering since its internal format is very similar to the JSON (JavaScript Object Notation) that tweets come in).\n",
    "\n",
    "At this point we will simply write the text and ID number of each tweet to a file.  We do this using `with open...` because this method of opening a file will ensure that it will close properly if the program crashes/halts unexpectedly, something that in inevitable at this point because the only way we have to stop the code we are running right now is to interrupt it.  There is some casting values to strings using the `str` function when writing to the output file because the ` .write() `  method requires a single string as an input.  Note as well the addition of the line break (`\\n`) to ensure that each tweet body starts on a new line.\n",
    "\n",
    "[Note that if you are a Windows user then you may have difficulty saving this file because of the character encoding used.  I'm working on finding a reliable fix for this.  Setting the encoding to utf-8, as is done below, seems to work in many but not all cases.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_TERM = 'potato'\n",
    "\n",
    "r = api.request('statuses/filter', {'track': TRACK_TERM})\n",
    "\n",
    "with open(\"streamTweets.csv\",\"a\",encoding=\"utf-8\") as outfile:\n",
    "    for item in r.get_iterator():\n",
    "        line = item['text'] + ',' + str(item['id'])\n",
    "        print(line if 'text' in item else item)\n",
    "        outfile.write((line + '\\n') if 'text' in item else item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output (there should be a file called \"streamTweets.csv\" in the same directory as this notebook) we can see that the body of each tweet is printed on its own line followed by a comma which is followed by the tweet ID... mostly.  Scrolling through the list will reveal that there are tweets that span multiple lines and blank spaces.  Why is this?  The body of some tweets includes line break characters (` \\n `).\n",
    "\n",
    "If we compare what was printed to the screen to what was written in the file we'll see the `\\n`'s on the screen translated to blank lines in the file.\n",
    "\n",
    "While there is an argument to be made that removing these characters makes no difference to the content of the tweet the counterargument is that line breaks are important punctuation and should be kept with the original tweet.  We will keep the line breaks.\n",
    "\n",
    "A popular way to do this would be to use a regular expression and replace each `\\n` that occurs with a `\\\\\\\\n` so that each `\\` is appropriately escaped as it is passed from the variable to the file.  The problem with this method is that there are other characters that might appear as well (either in tweets or elsewhere) and while we could write a regular expression to do the substitution in each case Python offers a better way: the [representation function](https://docs.python.org/3.5/library/functions.html#repr).  To do this we pass the line variable to the function `repr` as we write it to the output file, as in the example below.\n",
    "\n",
    "(Remember to stop the cell after a few seconds.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_TERM = 'trump'\n",
    "\n",
    "r = api.request('statuses/filter', {'track': TRACK_TERM})\n",
    "\n",
    "with open(\"sentimentTest.csv\",\"a\") as outfile:\n",
    "    for item in r.get_iterator():\n",
    "        line = item['text'] + ',' + str(item['id'])\n",
    "        print(line if 'text' in item else item)\n",
    "        outfile.write((repr(line) + '\\n') if 'text' in item else item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking streamTweets.csv shows that this approach is working well.  While we won't write to an output file in every example in the rest of this workbook keep in mind that you can use the same methods in all the examples that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Standard Search API](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets) allows for searching in the past 7 days.  It is rate limited to 180 requests per 15 minutes using oAuth1 and 450 requests per 15 minute using oAuth2.  It is also \"not exhaustive\", meaning that the full body of tweets matching search criteria within the window is unlikely to be returned (maybe if the body of tweets is very small).\n",
    "\n",
    "We'll shift away from the politically hot topic of Donald Trump to the topic of pizza for these next examples.\n",
    "\n",
    "Note the use of the `.get_quota()` method on the response object in order to see how much of our quota remains.  That's right, there are quotas on the free account we are using.  If you're only looking back 7 days then you only have to worry about being rate limited.  If you're looking back farther then you can make up to 250 requests per month to the 30-Day API and up to 50 requests per month to the Full Archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ecaorg @HRDMinistry Online classes are important and need of the hour. Because in this crucial time we cannot send‚Ä¶ https://t.co/WDCcsgWFkr\n",
      "I just know when we go back to school no ones going to follow any sort of social distancing guidelines, will party‚Ä¶ https://t.co/MeYT4wsbF2\n",
      "one of my students just facetimed me to ask when we‚Äôre going back to school. he‚Äôs so worried about a covid outbreak‚Ä¶ https://t.co/78zJoRBAWH\n",
      "over half are worried that Asian children are going to be bullied when they return to school due to the COVID-19 outbreak\n",
      "Boise State is stopping voluntary workouts due to eight positive or presumed positive COVID-19 tests on campus in t‚Ä¶ https://t.co/zURKpN4X3J\n",
      "Article on similar conditions in the Parc Ex district in Montreal, thanks for sharing @sashamd.\n",
      "\n",
      "‚ÄúWe used to learn‚Ä¶ https://t.co/FpKroaYDZn\n",
      "The Little Village Fiesta Patria Festival and 26th Street Mexican Independence Parade have been cancelled: https://t.co/3pO6xOQZW4\n",
      "More details on a COVID-19 outbreak among students, what Catholic schools plan to do to keep students safe when sch‚Ä¶ https://t.co/QG6Eg2Qqi1\n",
      "lowkey hope there‚Äôs an outbreak of covid in winter so we dont have to go to school\n",
      "The outbreak of #COVID19 not only cost many students a traditional end to their school year, it also cost Duval Cou‚Ä¶ https://t.co/mkV7oQapSI\n",
      "The death penalty trial of the man charged with killing 17 people at a Florida high school is off indefinitely beca‚Ä¶ https://t.co/QWBjUKlDlv\n",
      "@dropoutnation @ehaspel @arotherham @kevincarey1 @AaronRHanlon @laurenonthehill @ConorPWilliams eg https://t.co/M8vgLaS76m\n",
      "This helpful guide from @nasponline has some great resources and tips from school psychologists about how to help k‚Ä¶ https://t.co/h2ExM76KeN\n",
      "THIS JUST IN: The death penalty trial of the man charged with killing 17 people at Marjory Stoneman Douglas High Sc‚Ä¶ https://t.co/b5fxOfA7p1\n",
      "@WISE_Tweets A3: Quality distance learning Programs to address the COVID-19 outbreak.The programs can be designed t‚Ä¶ https://t.co/vlts21RDVl\n",
      "\n",
      "QUOTA: {'remaining': 179, 'limit': None, 'reset': None}\n"
     ]
    }
   ],
   "source": [
    "SEARCH_TERM = 'covid school outbreak -rt'\n",
    "\n",
    "r = api.request('search/tweets', {'q': SEARCH_TERM})\n",
    "\n",
    "for item in r.get_iterator():\n",
    "    print(item['text'] if 'text' in item else item)\n",
    "\n",
    "print('\\nQUOTA: %s' % r.get_quota())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be working but there are not many tweets being returned.  We can increase this by specifying the `count` parameter.  We'll also add a simple counter just to see what we are actually getting.  \n",
    "\n",
    "The set of all the parameters that can be invoked is available [HERE](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_TERM = '#pizza'\n",
    "COUNT = 100 \n",
    "\n",
    "r = api.request('search/tweets', {'q': SEARCH_TERM, 'count': COUNT})\n",
    "\n",
    "a = 1\n",
    "for item in r.get_iterator():\n",
    "    print(a)\n",
    "    print(item['text'] if 'text' in item else item)\n",
    "    a=a+1\n",
    "\n",
    "print('\\nQUOTA: %s' % r.get_quota())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, not 100 tweets but certainly more than before.  To go back further we'll need to look at paging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter returns results in chunks that are called \"pages\".  In the example above we are seeing just the first page of results and setting the `count` parameter to the maximum number of possible results returnable per page.  If you want to go back further then it becomes necessary to send multiple requests to the API in succession with each one asking for the next page.  While this can be implemented \"by hand\" TwitterAPI makes this much easier by providing a paging function called 'TwitterPager' (You can read more about it [HERE](https://geduldig.github.io/TwitterAPI/paging.html) that does all of the heavy lifting for you by tracking what page to ask for, ensuring the request rate is not too high, and generally managing the connection.  It is invoked in an almost identical way to everything you have seen so far in this workbook.\n",
    "\n",
    "Unlike the previous examples where we were printing out the body of each tweet here we will print out only the date the tweet was created and the ID.  This is done simply because it makes it easier to track what is happening.\n",
    "\n",
    "It is important to note that as with the streaming API endpoint you will need to stop the code at some point.  While you will eventually hit the 7-day limit it is unlikely that you want to wait that long for this toy example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterPager\n",
    "\n",
    "SEARCH_TERM = 'pizza'\n",
    "COUNT = 100\n",
    "\n",
    "pager = TwitterPager(api, 'search/tweets', {'q': SEARCH_TERM, 'count': COUNT})\n",
    "\n",
    "for item in pager.get_iterator():\n",
    "    #print(item['text'] if 'text' in item else item)\n",
    "    print((item['created_at'], item['id']) if 'text' in item else item)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note that as the code runs the dates and the tweet IDs both roll backwards and the search tool moves from the present (tweets become accessible via the search APIs about 30 seconds after they are created) to the past.\n",
    "\n",
    "The TwitterAPI documentation provides some [advanced ways to add fault tolerance](https://geduldig.github.io/TwitterAPI/faulttolerance.html).  These are fairly sophisticated and involve checking status codes and the like.  While valuable it is inevitable that you will end up halting your program for one reason or another and need it to restart scraping where it left off.  \n",
    "\n",
    "The code below does this by first checking to see if there is an object called \"item\" that has a value keyed to 'id'.  If it does then it captures this ID and uses it as input into the TwitterPager function so that all new tweets collected will be earlier than it.  If the value does not exist then an empty string is assigned as the ID to start from which the TwitterAPI will ignore and start providing input from the present.\n",
    "\n",
    "This code will work as long as the notebook stays open, no matter how often the cell is interrupted.  If you close the notebook and reopen it then you'll need to pass in the ID value from the last line of the output file to restart in the correct location.  If you need a more sophisticated method for handling faults then follow the link above to the TwitterAPI documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterPager\n",
    "\n",
    "SEARCH_TERM = 'pizza'\n",
    "COUNT = 100\n",
    "\n",
    "try:\n",
    "    SINCE_ID = item['id']\n",
    "except:\n",
    "    SINCE_ID = ''\n",
    "\n",
    "pager = TwitterPager(api, 'search/tweets', {'q': SEARCH_TERM, 'count': COUNT,'since_id':SINCE_ID})\n",
    "\n",
    "with open(\"restartTweetsTest.csv\",\"a\", encoding=\"utf-8\") as outfile:\n",
    "    for item in pager.get_iterator():\n",
    "            line = item['text'] + ',' + str(item['id'])\n",
    "            print(line if 'text' in item else item)\n",
    "            outfile.write((repr(line) + '\\n') if 'text' in item else item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premium Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access beyond stream filtering and searching imperfectly through the past 7 days requires some extra steps beyond simply making an app.\n",
    "\n",
    "1. Setting up a dev environment.  Within the Twitter developer site click on your name in the top right corner.  From the menu select \"Dev environments\".  Follow the interface to create the environments that you would like and associate an app with each.\n",
    "2. Note the name of each dev environment because it will go into one of the variables called `LABEL`, below.  I named my 30-Day development environment \"30DayTesting\" and my full archive development environment \"fullArchiveTesting\".  So in the 30 Day example I set `LABEL` to \"30DayTesting\" and in the Full Archive example I set `LABEL` to \"fullArchiveTesting\".\n",
    "\n",
    "To see exactly what is available in the premium sandbox have a look at the overview [HERE](https://developer.twitter.com/en/docs/tweets/search/overview/premium.html) and the search guide [HERE](https://developer.twitter.com/en/docs/tweets/search/guides/premium-operators).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate Limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search of the 7-day archive that we have done and the searches of the 30-day archive and the full archive that we are about to do are all subject to rate limits.  These matter less for the 7-day archive because its quotas reset every 15 minutes while there are quotas attached the premium apis that reset only once per month.  Failure to respect these will result in Twitter rejecting your search requests until your quota refreshes, typically with an error code of 429.\n",
    "\n",
    "The limits for the Standard API can be seen [HERE](https://developer.twitter.com/en/docs/basics/rate-limits.html).  To see the current quota status for your account that apply to accessing the 7-day archive you can run the code block immediately below [Note that this code block also demonstrates the basics of using the Python requests library to access the Twitter API rather than the TwitterAPI library.].  There is also the `.get_quotas` method within the TwitterAPI that was used above but this shows substantially less information [and it is not currently clear to me why it is different...].\n",
    "\n",
    "To see the subscription usage for your premium account you can log into your developer account on the Twitter website, click on your name in the top right corner, and then choose \"Subscriptions\" (the direct link should be [https://developer.twitter.com/en/account/subscriptions]()).  This will give you a dashboard with content that looks like the following:\n",
    "\n",
    "![](twitterSubscriptionDashboard.png)\n",
    "\n",
    "The limits you will held to (unless you pay to upgrade) will be as follows:\n",
    "\n",
    "* fullarchive: 50 searches/month and a total of 5,000 tweets returned\n",
    "* 30day: 250 searches/month and a total of 25,000 tweets returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also limits on the number of times you can hit various APIs, typically within a 15 minute window.  To see some of these you can run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to do this came from https://stackoverflow.com/questions/33308634/how-to-perform-oauth-when-doing-twitter-scraping-with-python-requests\n",
    "\n",
    "import requests\n",
    "from requests_oauthlib import OAuth1\n",
    "import json\n",
    "\n",
    "url = 'https://api.twitter.com/1.1/account/verify_credentials.json'\n",
    "auth = OAuth1(API_KEY, API_KEY_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "requests.get(url, auth=auth)\n",
    "\n",
    "# using 'rr' as the variable to ensure that any work done above when the variable was 'r'\n",
    "# isn't overwritten.\n",
    "rr = requests.get('https://api.twitter.com/1.1/application/rate_limit_status.json?resources=help,users,search,statuses', auth=auth)\n",
    "\n",
    "print(json.dumps(json.loads(rr.text), indent=3, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are being limited in your search results and running the cell above doesn't illuminate why this is so and neither does the subscription dashboard then running one of the following code cells might.  The first is a direct probe of the 30 Day endpoint and the second is a probe of the full archive.  \n",
    "\n",
    "Remember that you need to run the appropriate authorization code at the top of this workbook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probe of 30 Day endpoint\n",
    "r = requests.get('https://api.twitter.com/1.1/tweets/search/30day/30DayTesting.json?query=pizza', auth=auth)\n",
    "print(json.dumps(json.loads(r.text), indent=3, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probe of Full Archive\n",
    "r = requests.get('https://api.twitter.com/1.1/tweets/search/fullarchive/fullArchiveTesting.json?query=physicalactivityandpregnancy', auth=auth)\n",
    "print(json.dumps(json.loads(r.text), indent=3, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example on how to access the 30 Day archive can be seen immediately below.  Keep in mind that the limits on the 30 Day archive sandbox are significantly higher than those associated with the Full Archive sandbox so you'll want to catch tweets that you can't grab from the standard search before they move out of this rolling window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "SEARCH_TERM = 'pizza'\n",
    "PRODUCT = '30day'\n",
    "LABEL = '30DayTesting'\n",
    "\n",
    "r = api.request('tweets/search/%s/:%s' % (PRODUCT, LABEL), \n",
    "                {'query':SEARCH_TERM})\n",
    "\n",
    "for item in r:\n",
    "    print(item['text'] if 'text' in item else item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.text #you can run this if you need to see what the text of the last item was for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where _almost_ all the tweets that have ever been published can be found.  What tweets are not included?  Those that have been deleted or corrected for whatever reason.  If you want deleted tweets then you'll need access to some archive that scraped them before they were deleted.  If they were edited (possibly with a Chrome extension called [Covfefe](https://chrome.google.com/webstore/detail/covfefe/ccdjnhaifeigaidilnnajickpbjhbfom)) you are likely in a similar situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "SEARCH_TERM = 'pizza'\n",
    "PRODUCT = 'fullarchive'\n",
    "LABEL = 'fullArchiveTesting'\n",
    "\n",
    "r = api.request('tweets/search/%s/:%s' % (PRODUCT, LABEL), \n",
    "                {'query':SEARCH_TERM})\n",
    "\n",
    "for item in r:\n",
    "    print(item['text'] if 'text' in item else item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.text #you can run this if you need to see what the text of the last item was for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have been tracking the text of the tweets you'll likely notice that many of them are incomplete, containing `...`.  This is a result of Twitter's new extended tweet mechanism that enables tweets of up to 280 characters instead of the original 140.  To get the full text of a tweet in every case you need to see if it is an extended tweet and, if it is, then look elsewhere in the tweet for the full text, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Full Archive Tweets with full text and tweet full information\n",
    "from TwitterAPI import TwitterAPI, TwitterPager\n",
    "\n",
    "SEARCH_TERM = 'POTUS'\n",
    "PRODUCT = 'fullarchive'\n",
    "LABEL = 'fullArchiveTesting'\n",
    "\n",
    "r = api.request('tweets/search/%s/:%s' % (PRODUCT, LABEL), {'query': SEARCH_TERM})\n",
    "\n",
    "#with open(\"restartTweetsTest.csv\",\"a\", encoding=\"utf-8\") as outfile:\n",
    "for item in r:\n",
    "    if 'extended_tweet' in item.keys():\n",
    "        tweet_text = \"EXTENDED: \" + item['extended_tweet']['full_text']\n",
    "    else:\n",
    "        tweet_text = \"ORIGINAL:\" + item['text']\n",
    "    print(tweet_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Archive with Paging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the premium search documentation and note that some of the features supported with searching the seven day archive are not supported on the 30 Day or Full Archive API.  For example, specifying a  maximum number of results to return or the what ID to search since is not available (see [HERE](https://developer.twitter.com/en/docs/tweets/search/api-reference/premium-search)).\n",
    "\n",
    "Note the code below which amalgamates the full archive example just shown with the paging example from earlier in this workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Archive Tweets without full text\n",
    "from TwitterAPI import TwitterAPI, TwitterPager\n",
    "\n",
    "SEARCH_TERM = 'pizza'\n",
    "PRODUCT = 'fullarchive'\n",
    "LABEL = 'fullArchiveTesting'\n",
    "\n",
    "pager = TwitterPager(api, 'tweets/search/%s/:%s' % (PRODUCT, LABEL), {'query': SEARCH_TERM})\n",
    "\n",
    "#with open(\"restartTweetsTest.csv\",\"a\", encoding=\"utf-8\") as outfile:\n",
    "for item in pager.get_iterator(wait=30):\n",
    "    line = item['text'] + '|' + str(item['id']) + '|' + str(item['created_at']) + '|' + str(item['user']['location']) + '|' + str(item['user']['name']) + '|' + str(item['user']['screen_name'])\n",
    "    print(line if 'text' in item else item)\n",
    "    #outfile.write((repr(line) + '\\n') if 'text' in item else item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you have a retweet of an extended tweet then the only way to get the full content is to grab the original tweet.  This can be done using the information in the retweet but this is not currently covered here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Date Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding date ranges to searches of the Full Archive is an essential task given that within the sandbox you'll only be able to collect up to 5k tweets per month.  This is easily done by passing a `fromdate` value and a `todate` value within the curly braces that the value for `query` is passed.  This is shown below in a code block that also incorporates extended tweets and paging through results.\n",
    "\n",
    "Note that this is not a block of code to just let run since it will consume part of your full archive access for the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI, TwitterPager\n",
    "\n",
    "SEARCH_TERM = 'pizza'\n",
    "PRODUCT = 'fullarchive'\n",
    "LABEL = 'fullArchiveTesting'\n",
    "\n",
    "pager = TwitterPager(api, 'tweets/search/%s/:%s' % (PRODUCT, LABEL), {'query': SEARCH_TERM, 'fromDate': 20180917000,'toDate':20180918000})\n",
    "\n",
    "pagerObject =[]\n",
    "\n",
    "    if 'extended_tweet' in item.keys():\n",
    "        tweet_text = item['extended_tweet']['full_text']\n",
    "    else:\n",
    "        tweet_text = item['text']\n",
    "    line = tweet_text + '|' + str(item['id']) + '|' + str(item['created_at']) + '|' + str(item['user']['location']) + '|' + str(item['user']['name']) + '|' + str(item['user']['screen_name'])\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're going to be collecting a lot of tweets then keeping them all in .csv files (as above) will likely become detrimental at some point unless your workflow is always going to involve processing each of these files in its entirety.  If you're ever going to want to search quickly for content within what you have collected and possibly on across a range of features then you should consider load the tweets you collect into a database as you collect them.\n",
    "\n",
    "There are many databases that you could choose for doing this but the one we will cover here is MongoDB.  Why?  The Community Edition (aka \"The Free Version\") is robust enough to handle many research tasks, it has decent performance, there is a handy tool that accompanies it that you can use to interact with the database outside of Python, and how MongoDB stores the items it holds (usually called \"posts\") is pretty much JSON, which is the format the the tweets are returned in.  So, a pretty nice fit.\n",
    "\n",
    "This notebook is not going to cover how to install MongoDB Community Edition but the instructions you should be looking at are [HERE](https://docs.mongodb.com/manual/administration/install-community/).  Note that these instructions require that MongoDB is restarted as a service each time the computer is turned back on.  If you want to have it autostart then you'll need to do some searching for a solution that fits your operating system.\n",
    "\n",
    "A free tool for interacting with MongoDB without some programming language is Robo3t (formerly \"Robomongo\").  It can be downloaded [HERE](https://robomongo.org/download).  If you need more power then the paid version‚ÄîSudio3T‚Äîis available from the same place.\n",
    "\n",
    "The rest of this section assumes that you have installed MongoDB _and that it is running_.  If you are using this workbook as part of a webinar then regardless of whether you are following along in Google Colab or on your own machine this is not likely to be the case and so you'll likely need to simply look at how this is done in principle.  If you are using Colab and would like to try MongoDB then a method for doing so is [HERE](https://colab.research.google.com/github/Giffy/MongoDB_PyMongo_Tutorial/blob/master/1_Run_MongoDB_in_colab.ipynb#scrollTo=8IxGGMVFnWgx)(Note the caveat that your data will be deleted after 12 hours)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by installing the library that will let us connect to the instance of MongoDB that _you already have running in the background_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /Users/simpson/anaconda3/lib/python3.7/site-packages (3.10.1)\r\n"
     ]
    }
   ],
   "source": [
    "#run this if you need to install pymongo, the library that lets python interact with MongoDB\n",
    "\n",
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the pymongo library is installed we can import it into our current session.  Note the creation of the variable `client`.  By default MongoDB is listening on port 27017 for connections and this is where that connection information is passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create/connect to a database called `testDB` and assign the connection to that database to the variable `db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.testDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database itself is not actually where the information is stored in MongoDB.  It has a substructure called a \"collection\" and so we'll create one called \"testCollection\" and assign it to the variable `posts` for collecting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = db.testCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the variable `posts` basically expands to MongoClient('localhost', 27017).testDB.testCollection.  We use `db` and `posts` as variables because it simplifies writing out the entire string of connection information.\n",
    "\n",
    "Now that we have the connection information sorted out we can carry out a search and add the content to the database, as below.  Note the structures related to TwitterAPI that are taken from the above sections.  The new steps are the creation of a dictionary object (essentially a piece of JSON if you're not familiar with dictionaries) in `post = {\"text\": tweet_text ... }`.  Note that a design decision is being made about what to call the items being stored in the database.  `tweet_text` is what the Twitter API returns as the key to accessing the content of the tweet.  Setting this to be `text` for the entry in our database is a choice.  You can modify or keep the key/field names as works for you.  If you do not need to keep the entire content of a tweet then there is likely little point in replicating the format of the tweet exactly.\n",
    "\n",
    "`posts.insert_one(post)` is the instruction that writes the content of the tweet in `post` to the collection in the database.  The pymongo method `insert_one` returns the id of the inserted content which we capture here with `post_id` and then print to the screen on the next line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ecea7244921c1eb2a74cf83\n",
      "5ecea7244921c1eb2a74cf84\n",
      "5ecea7244921c1eb2a74cf85\n",
      "5ecea7244921c1eb2a74cf86\n",
      "5ecea7244921c1eb2a74cf87\n",
      "5ecea7244921c1eb2a74cf88\n",
      "5ecea7244921c1eb2a74cf89\n",
      "5ecea7244921c1eb2a74cf8a\n",
      "5ecea7244921c1eb2a74cf8b\n",
      "5ecea7244921c1eb2a74cf8c\n",
      "5ecea7244921c1eb2a74cf8d\n",
      "5ecea7254921c1eb2a74cf8e\n",
      "5ecea7254921c1eb2a74cf8f\n",
      "5ecea7254921c1eb2a74cf90\n",
      "5ecea7254921c1eb2a74cf91\n",
      "5ecea7254921c1eb2a74cf92\n",
      "5ecea7254921c1eb2a74cf93\n",
      "5ecea7254921c1eb2a74cf94\n",
      "5ecea7254921c1eb2a74cf95\n",
      "5ecea7254921c1eb2a74cf96\n",
      "5ecea7254921c1eb2a74cf97\n",
      "5ecea7254921c1eb2a74cf98\n",
      "5ecea7254921c1eb2a74cf99\n",
      "5ecea7254921c1eb2a74cf9a\n",
      "5ecea7254921c1eb2a74cf9b\n",
      "5ecea7254921c1eb2a74cf9c\n",
      "5ecea7254921c1eb2a74cf9d\n",
      "5ecea7254921c1eb2a74cf9e\n",
      "5ecea7254921c1eb2a74cf9f\n",
      "5ecea7264921c1eb2a74cfa0\n",
      "5ecea7264921c1eb2a74cfa1\n",
      "5ecea7264921c1eb2a74cfa2\n",
      "5ecea7264921c1eb2a74cfa3\n",
      "5ecea7264921c1eb2a74cfa4\n",
      "5ecea7264921c1eb2a74cfa5\n",
      "5ecea7264921c1eb2a74cfa6\n",
      "5ecea7264921c1eb2a74cfa7\n",
      "5ecea7264921c1eb2a74cfa8\n",
      "5ecea7264921c1eb2a74cfa9\n",
      "5ecea7264921c1eb2a74cfaa\n",
      "5ecea7264921c1eb2a74cfab\n",
      "5ecea7264921c1eb2a74cfac\n",
      "5ecea7264921c1eb2a74cfad\n",
      "5ecea7264921c1eb2a74cfae\n",
      "5ecea7264921c1eb2a74cfaf\n",
      "5ecea7274921c1eb2a74cfb0\n",
      "5ecea7274921c1eb2a74cfb1\n",
      "5ecea7274921c1eb2a74cfb2\n",
      "5ecea7274921c1eb2a74cfb3\n",
      "5ecea7274921c1eb2a74cfb4\n",
      "5ecea7274921c1eb2a74cfb5\n",
      "5ecea7284921c1eb2a74cfb6\n",
      "5ecea7284921c1eb2a74cfb7\n",
      "5ecea7284921c1eb2a74cfb8\n",
      "5ecea7284921c1eb2a74cfb9\n",
      "5ecea7284921c1eb2a74cfba\n",
      "5ecea7284921c1eb2a74cfbb\n",
      "5ecea7284921c1eb2a74cfbc\n",
      "5ecea7284921c1eb2a74cfbd\n",
      "5ecea7284921c1eb2a74cfbe\n",
      "5ecea7284921c1eb2a74cfbf\n",
      "5ecea7284921c1eb2a74cfc0\n",
      "5ecea7284921c1eb2a74cfc1\n",
      "5ecea7284921c1eb2a74cfc2\n",
      "5ecea7284921c1eb2a74cfc3\n",
      "5ecea7284921c1eb2a74cfc4\n",
      "5ecea7284921c1eb2a74cfc5\n",
      "5ecea7284921c1eb2a74cfc6\n",
      "5ecea7294921c1eb2a74cfc7\n",
      "5ecea7294921c1eb2a74cfc8\n",
      "5ecea7294921c1eb2a74cfc9\n",
      "5ecea7294921c1eb2a74cfca\n",
      "5ecea7294921c1eb2a74cfcb\n",
      "5ecea7294921c1eb2a74cfcc\n",
      "5ecea7294921c1eb2a74cfcd\n",
      "5ecea7294921c1eb2a74cfce\n",
      "5ecea7294921c1eb2a74cfcf\n",
      "5ecea7294921c1eb2a74cfd0\n",
      "5ecea7294921c1eb2a74cfd1\n",
      "5ecea7294921c1eb2a74cfd2\n",
      "5ecea7294921c1eb2a74cfd3\n",
      "5ecea7294921c1eb2a74cfd4\n",
      "5ecea7294921c1eb2a74cfd5\n",
      "5ecea7294921c1eb2a74cfd6\n",
      "5ecea7294921c1eb2a74cfd7\n",
      "5ecea7294921c1eb2a74cfd8\n",
      "5ecea7294921c1eb2a74cfd9\n",
      "5ecea7294921c1eb2a74cfda\n",
      "5ecea7294921c1eb2a74cfdb\n",
      "5ecea7294921c1eb2a74cfdc\n",
      "5ecea7294921c1eb2a74cfdd\n",
      "5ecea7294921c1eb2a74cfde\n",
      "5ecea7294921c1eb2a74cfdf\n",
      "5ecea7294921c1eb2a74cfe0\n",
      "5ecea7294921c1eb2a74cfe1\n",
      "5ecea7294921c1eb2a74cfe2\n",
      "5ecea7294921c1eb2a74cfe3\n",
      "5ecea7294921c1eb2a74cfe4\n",
      "5ecea7294921c1eb2a74cfe5\n",
      "5ecea7294921c1eb2a74cfe6\n"
     ]
    }
   ],
   "source": [
    "SEARCH_TERM = 'corona virus'\n",
    "COUNT = 100\n",
    "MODE = 'extended'\n",
    "\n",
    "r = api.request('search/tweets', {'q': SEARCH_TERM, 'count': COUNT, 'mode': MODE})\n",
    "\n",
    "for item in r.get_iterator():\n",
    "    tweet_text = repr(item['text'])\n",
    "    post = {\"text\": tweet_text,\n",
    "        \"id\": str(item['id']),\n",
    "        \"created_at\": str(item['created_at']),\n",
    "        \"user_location\": str(item['user']['location']),\n",
    "        \"user_name\": str(item['user']['screen_name']),\n",
    "        \"search_term\": SEARCH_TERM}\n",
    "    post_id = posts.insert_one(post).inserted_id\n",
    "    print(post_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, if you really want (or don't mind) all the content of all the tweets collected then you can significantly reduce what is needed to input each tweet into the collection in the database.  Note that this works because `item` is a dictionary given both the Twitter API and the library that we are using to access it (TwitterAPI, no space).  If you use another library to scrape tweets then you may have to do some additional work in advance of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ecea7e34921c1eb2a74cfe7\n",
      "5ecea7e34921c1eb2a74cfe8\n",
      "5ecea7e34921c1eb2a74cfe9\n",
      "5ecea7e34921c1eb2a74cfea\n",
      "5ecea7e34921c1eb2a74cfeb\n",
      "5ecea7e34921c1eb2a74cfec\n",
      "5ecea7e34921c1eb2a74cfed\n",
      "5ecea7e34921c1eb2a74cfee\n",
      "5ecea7e34921c1eb2a74cfef\n",
      "5ecea7e34921c1eb2a74cff0\n",
      "5ecea7e34921c1eb2a74cff1\n",
      "5ecea7e34921c1eb2a74cff2\n",
      "5ecea7e34921c1eb2a74cff3\n",
      "5ecea7e34921c1eb2a74cff4\n",
      "5ecea7e34921c1eb2a74cff5\n",
      "5ecea7e34921c1eb2a74cff6\n",
      "5ecea7e34921c1eb2a74cff7\n",
      "5ecea7e34921c1eb2a74cff8\n",
      "5ecea7e34921c1eb2a74cff9\n",
      "5ecea7e34921c1eb2a74cffa\n",
      "5ecea7e34921c1eb2a74cffb\n",
      "5ecea7e34921c1eb2a74cffc\n",
      "5ecea7e44921c1eb2a74cffd\n",
      "5ecea7e44921c1eb2a74cffe\n",
      "5ecea7e44921c1eb2a74cfff\n",
      "5ecea7e44921c1eb2a74d000\n",
      "5ecea7e44921c1eb2a74d001\n",
      "5ecea7e44921c1eb2a74d002\n",
      "5ecea7e44921c1eb2a74d003\n",
      "5ecea7e44921c1eb2a74d004\n",
      "5ecea7e44921c1eb2a74d005\n",
      "5ecea7e44921c1eb2a74d006\n",
      "5ecea7e44921c1eb2a74d007\n",
      "5ecea7e44921c1eb2a74d008\n",
      "5ecea7e44921c1eb2a74d009\n",
      "5ecea7e44921c1eb2a74d00a\n",
      "5ecea7e44921c1eb2a74d00b\n",
      "5ecea7e44921c1eb2a74d00c\n",
      "5ecea7e44921c1eb2a74d00d\n",
      "5ecea7e44921c1eb2a74d00e\n",
      "5ecea7e44921c1eb2a74d00f\n",
      "5ecea7e44921c1eb2a74d010\n",
      "5ecea7e44921c1eb2a74d011\n",
      "5ecea7e44921c1eb2a74d012\n",
      "5ecea7e44921c1eb2a74d013\n",
      "5ecea7e44921c1eb2a74d014\n",
      "5ecea7e44921c1eb2a74d015\n",
      "5ecea7e44921c1eb2a74d016\n",
      "5ecea7e44921c1eb2a74d017\n",
      "5ecea7e44921c1eb2a74d018\n",
      "5ecea7e44921c1eb2a74d019\n",
      "5ecea7e54921c1eb2a74d01a\n",
      "5ecea7e54921c1eb2a74d01b\n",
      "5ecea7e54921c1eb2a74d01c\n",
      "5ecea7e54921c1eb2a74d01d\n",
      "5ecea7e64921c1eb2a74d01e\n",
      "5ecea7e64921c1eb2a74d01f\n",
      "5ecea7e64921c1eb2a74d020\n",
      "5ecea7e64921c1eb2a74d021\n",
      "5ecea7e64921c1eb2a74d022\n",
      "5ecea7e64921c1eb2a74d023\n",
      "5ecea7e64921c1eb2a74d024\n",
      "5ecea7e74921c1eb2a74d025\n",
      "5ecea7e74921c1eb2a74d026\n",
      "5ecea7e74921c1eb2a74d027\n",
      "5ecea7e74921c1eb2a74d028\n",
      "5ecea7e74921c1eb2a74d029\n",
      "5ecea7e74921c1eb2a74d02a\n",
      "5ecea7e74921c1eb2a74d02b\n",
      "5ecea7e74921c1eb2a74d02c\n",
      "5ecea7e74921c1eb2a74d02d\n",
      "5ecea7e74921c1eb2a74d02e\n",
      "5ecea7e74921c1eb2a74d02f\n",
      "5ecea7e74921c1eb2a74d030\n",
      "5ecea7e74921c1eb2a74d031\n",
      "5ecea7e74921c1eb2a74d032\n",
      "5ecea7e74921c1eb2a74d033\n",
      "5ecea7e74921c1eb2a74d034\n",
      "5ecea7e74921c1eb2a74d035\n",
      "5ecea7e74921c1eb2a74d036\n",
      "5ecea7e74921c1eb2a74d037\n",
      "5ecea7e74921c1eb2a74d038\n",
      "5ecea7e74921c1eb2a74d039\n",
      "5ecea7e74921c1eb2a74d03a\n",
      "5ecea7e74921c1eb2a74d03b\n",
      "5ecea7e74921c1eb2a74d03c\n",
      "5ecea7e74921c1eb2a74d03d\n",
      "5ecea7e74921c1eb2a74d03e\n",
      "5ecea7e74921c1eb2a74d03f\n",
      "5ecea7e74921c1eb2a74d040\n",
      "5ecea7e74921c1eb2a74d041\n",
      "5ecea7e84921c1eb2a74d042\n",
      "5ecea7e84921c1eb2a74d043\n",
      "5ecea7e84921c1eb2a74d044\n",
      "5ecea7e84921c1eb2a74d045\n",
      "5ecea7e84921c1eb2a74d046\n",
      "5ecea7e84921c1eb2a74d047\n",
      "5ecea7e84921c1eb2a74d048\n",
      "5ecea7e84921c1eb2a74d049\n",
      "5ecea7e84921c1eb2a74d04a\n"
     ]
    }
   ],
   "source": [
    "SEARCH_TERM = 'corona virus'\n",
    "COUNT = 100\n",
    "MODE = 'extended'\n",
    "\n",
    "r = api.request('search/tweets', {'q': SEARCH_TERM, 'count': COUNT, 'mode': MODE})\n",
    "\n",
    "for item in r.get_iterator():\n",
    "    print(posts.insert_one(item).inserted_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data Out: Find One Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows you to find a Tweet matching a single criteria in a MongoDB collection.  If there is more than one document matching the search term then only the first match found is returned. user_name is used in this example. Note that this is searching for Tweets from the collection created by the above cells so they must be run in advance.  Also note that you will need an actual user_name from the data collected for this to work and so you will likely need to change the input value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5ecea7244921c1eb2a74cf83'),\n",
      " 'created_at': 'Wed May 27 17:45:05 +0000 2020',\n",
      " 'id': '1265700567596150784',\n",
      " 'search_term': 'corona virus',\n",
      " 'text': \"'RT @haaveumetanish: Corona virus vaccine be like: \"\n",
      "         \"https://t.co/9JdmXCBYyg'\",\n",
      " 'user_location': '',\n",
      " 'user_name': '10thchait'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(posts.find_one({\"user_name\": \"10thchait\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data Out: Find (All) Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method allows you to find all Tweets matching a specified criteria in a MongoDB collection. This example displays all the Tweets containing \"Minute\" in the text. Again, this will only search in one collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'RT @haaveumetanish: Corona virus vaccine be like: https://t.co/9JdmXCBYyg'\n",
      "'RT @haaveumetanish: Corona virus vaccine be like: https://t.co/9JdmXCBYyg'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @ahteshamBokhari: Hospital built in Islamabad in 40 days for corona virus patients. Imagine if this task would have been given to PPP ht‚Ä¶'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'10 new corona virus cases in #Tripura\\nTotal cases 242\\nTotal Cases in India 158052'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'No me canso de cagarme todos los d√≠as en el Corona virus üòÄ'\n",
      "'RT @IgHawthorne: Corona virus testing denied to autistic people &amp; people with learning disability.  THIS IS EUGENICS.\\nhttps://t.co/w7941jXm‚Ä¶'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'@makkox Libreria da corona virus... con voglia di mare https://t.co/6aMu9W9Aat'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @Skhamiisi: Mbonye is quiet these days ,he must be cooking some fake prophecies about who will end the corona virus .'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'Bem tranquilo sabendo que o coordenador do comit√™ contra corona virus acha que est√° tudo ok, dentro do esperado e d‚Ä¶ https://t.co/4aJyFoe1HE'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'@annsyam29 @FajarAl55275044 Hei mbak mbak haus birahi....\\n\\nLu kata LGBTQ+ itu virus corona?\\n\\nLGBTQ+ udah dari ada s‚Ä¶ https://t.co/LWFQzf940l'\n",
      "\"@montie I'm SO looking forward to the sheer calamity that Brexit will add to the impact of Corona-virus.....and the‚Ä¶ https://t.co/STgjQ1uXfi\"\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @Musa__Kalarawi: And suddenly people start to not give a damn about corona virus anymore. If you die you die, if you survive you survive‚Ä¶'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @iofbvhs: corona virus is a hoax invented by twentyonepilots just to drop a hit single about it so they can finish the trench era with a‚Ä¶'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'@SkyNews Ok tell the same when you die from corona virus.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @IgHawthorne: Corona virus testing denied to autistic people &amp; people with learning disability.  THIS IS EUGENICS.\\nhttps://t.co/w7941jXm‚Ä¶'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "'RT @bridgewhisperer: \\u2066@UM_CEE‚Äôs \\u2066@waterwiggi\\u2069 featured in \\u2066@nytimes\\u2069 article about studying corona virus spread looking at wastewater.  Con‚Ä¶'\n",
      "'RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.'\n",
      "RT @Solwayo1: @BusisaMoyo @iam4byo @limited_united And I warned, warned and warned until I was taken as an alarmist. The corona virus is no‚Ä¶\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "russian corona-virus 2 https://t.co/xLtXwzHzg3\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @Mendietaluzm: No me canso de cagarme todos los d√≠as en el Corona virus üòÄ\n",
      "@BJP4India @rsprasad A to sai hai ,,modi ji hi to des abhi bi sai hai, or corona virus jaisa bimari,,etni abadi des‚Ä¶ https://t.co/5NaJaM1ty8\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "can‚Äôt wait for this whole corona virus to be over. i just want to chill and vibe with good people.\n",
      "RT @YogeshR44594861: @adumbindian @mishra_burbak Breaking News : ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§≠‡§∞ ‡§Æ‡•á‡§Ç ‡§§‡§¨‡§æ‡§π‡•Ä ‡§Æ‡§ö‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡§æ Corona virus ‡§ï‡§≤ ‡§¨‡•Å‡§§‡§æ ‡§∏‡§æ‡§¨‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•Ä‡§µ‡§ø‚Ä¶\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @podoradong: Kondisi kota surabaya sudah parah dalam penanganan virus corona, Pemkot sudah tidak mampu mengendalikan dan kemampuan rumah‚Ä¶\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "A girl talked to me,\n",
      "She said: corona virus ek khatarnaak waba hai, isko apni caller tune bnanay ke liae 1 dabayyen\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "Corona virus se saia eu quero ir na casa dos meus amigos consolidar amizade vendo filme fofocando e comendo\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "Corona virus veio testar quanto tempo eu fico sem praia\n",
      "Data kematian corona itu 100% meninggal karena virus atau meninggal karena virus+penyakit lain yaa, hmm bingung sayaa.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @memcbrexit: So the EU are seeking to borrow ‚Ç¨750 billion in a corona virus recovery package &amp; a further ‚Ç¨1.1 trillion!over the next 7 y‚Ä¶\n",
      "RT @haaveumetanish: Corona virus vaccine be like: https://t.co/9JdmXCBYyg\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "Can corona virus please end so it‚Äôs easier for me to ask my new friends to hangout irl without being weird ü•¥\n",
      "@KyeTheHusky A'ight fam, lemme just hit up the CEO of corona virus and tell him enough is enough\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "A cloroquina lutando contra o corona virus https://t.co/6QeLfMOBNi\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @its_santu: In this current situation of pandemic corona virus, please stop any all kind of exam (H.S. and UG) announcement. After stabi‚Ä¶\n",
      "RT @BarabankiD: ‡§ú‡§®‡§™‡§¶ ‡§¨‡§æ‡§∞‡§æ‡§¨‡§Ç‡§ï‡•Ä ‡§Æ‡•á‡§Ç corona virus ‡§ï‡•á ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§Æ‡•á‡§Ç 121 active ‡§ï‡•á‡§∏ ‡§π‡•à‡§Ç‡•§\n",
      "‡§ö‡§ø‡§Ç‡§§‡§æ ‡§® ‡§ï‡§∞‡•á‡§Ç, ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§Æ‡•á‡§Ç ‡§π‡•à‡•§\n",
      "‡§è‡§ï ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§ø‡§Ø‡•á, ‡§ò‡§∞‚Ä¶\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "@SadhviPragya_MP Aap  Corona virus ko hi shraap kyun nahi de deti hai taaki Corona virus hi humesha liye Mar jaaye ?? üôèüôè\n",
      "\n",
      "#Lockdown5\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "@ferbelaunzaran @brozoxmiswebs @lopezobrador_ seguro quiere perseguir el Corona virus el muy pendejo üòÇüòÇüòÇ\n",
      "THE POTUS IS RIGHT..NO! NO! NO! TO MAIL IN VOTING! The DemoRats need to stop using this Chinese corona virus as an‚Ä¶ https://t.co/xFd43UpAtk\n",
      "RT @roadkilledaman: ppl: *social distancing less and less*\n",
      "\n",
      "the 2nd wave of corona virus: https://t.co/Z2hhjpt3uO\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "@ChroniclesNate That is the journey of corona virus.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "@sobviotxica El miedo le perdimos al hiv por el prep vuelve en forma de corona virus\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @yelyahwilliams: i hate the news. if it‚Äôs not corona virus it‚Äôs other diseases, like blatant fucking racism.\n",
      "RT @Ayush23067357: #GeneralPromotionToMPStudents\n",
      "Kyu MP government serious nii hai itni corona koi chota mota virus nii hai puri duniya me‚Ä¶\n",
      "1/2 \n",
      "\"Recently, chloroquine was shown to inhibit the replication and spread of corona virus in vitro [36, 37] and t‚Ä¶ https://t.co/LrkXdwsMTZ\n"
     ]
    }
   ],
   "source": [
    "#find() method\n",
    "for post in posts.find():\n",
    "    if \"virus\" in post['text']:\n",
    "        #pprint.pprint(post)\n",
    "        print(post['text'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
